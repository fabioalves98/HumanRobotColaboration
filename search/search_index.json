{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Thesis Proposal Bra\u00e7o Rob\u00f3tico e Humano Desempenham Tarefas de Forma Colaborativa Enquadramento e Motiva\u00e7\u00e3o Os bra\u00e7os rob\u00f3ticos industriais, na sua instala\u00e7\u00e3o cl\u00e1ssica e n\u00e3o colaborativa, executam as suas tarefas em espa\u00e7os nos quais est\u00e1 vedada a presen\u00e7a de humanos. Essa veda\u00e7\u00e3o pode ser f\u00edsica, atrav\u00e9s de jaulas, por exemplo, ou virtual. Por quest\u00f5es de seguran\u00e7a, tipicamente, o rob\u00f4 para se algu\u00e9m entrar dentro do espa\u00e7o de seguran\u00e7a. A Rob\u00f3tica Colaborativa representa uma nova forma de integrar os rob\u00f4s, e, em particular, os bra\u00e7os rob\u00f3ticos com capacidade de manipula\u00e7\u00e3o, em ambientes industriais. O princ\u00edpio \u00e9 fazer com que os rob\u00f4s colaborativos desempenhem as suas tarefas, de forma segura, em espa\u00e7os que s\u00e3o partilhados por humanos, e tamb\u00e9m que os rob\u00f4s colaborativos possam executar tarefas conjuntamente com humanos, colaborando para a execu\u00e7\u00e3o eficaz dessa tarefa. Avan\u00e7os recentes no hardware dos bra\u00e7os rob\u00f3ticos permitem novas funcionalidades como a execu\u00e7\u00e3o de movimentos em modo compliant ou a medi\u00e7\u00e3o de torques e for\u00e7as em v\u00e1rias juntas. \u00c9 tamb\u00e9m importante ter a capacidade de perceber as posi\u00e7\u00f5es do bra\u00e7o, humanos e outros objetos e melhorar as capacidades de intera\u00e7\u00e3o entre humano-rob\u00f4. Objetivos e plano de trabalhos O objetivo desta disserta\u00e7\u00e3o \u00e9 o desenvolvimento de t\u00e9cnicas que potenciem a partilha de espa\u00e7o entre humanos e um bra\u00e7o rob\u00f3tico inserido numa c\u00e9lula industrial. O rob\u00f4 deve interagir com o humano atrav\u00e9s de gestos e toque. Deve ser poss\u00edvel passar objetos ou ferramentas entre o humano e o rob\u00f4, e no sentido inverso. O rob\u00f4 deve colaborar com o humano na execu\u00e7\u00e3o das tarefas e deve movimentar-se de modo a assegurar a integridade f\u00edsica do(s) humano(s) presente(s) no seu espa\u00e7o de trabalho. A c\u00e9lula industrial est\u00e1 dotada de c\u00e2maras e outros sensores, como, por exemplo, Velodyne Lidar, para melhorar a percep\u00e7\u00e3o de todos os objetos e pessoas no espa\u00e7o de trabalho. As ferramentas a desenvolver dever\u00e3o estar integradas com ROS (Robot Operating System), podendo ser considerada a utiliza\u00e7\u00e3o da vers\u00e3o ROS ou da vers\u00e3o ROS2. Plano de Trabalhos Levantamento do estado da arte sobre rob\u00f3tica colaborativa, intera\u00e7\u00e3o humano-rob\u00f4 e percep\u00e7\u00e3o de ambientes industriais; Desenvolvimento de t\u00e9cnicas de intera\u00e7\u00e3o com o rob\u00f4 atrav\u00e9s de gestos e toque, ou outras modalidades; Desenvolvimento de t\u00e9cnicas que permitam a transfer\u00eancia de ferramentas ou outros objetos entre rob\u00f4 e humano; Desenvolvimento de t\u00e9cnicas de planeamento de movimentos que assegurem a seguran\u00e7a das opera\u00e7\u00f5es de manipula\u00e7\u00e3o do bra\u00e7o rob\u00f3tico, mesmo na presen\u00e7a de humanos/obst\u00e1culos m\u00f3veis. Teste e valida\u00e7\u00e3o das t\u00e9cnicas desenvolvidas. Reda\u00e7\u00e3o da disserta\u00e7\u00e3o","title":"Proposal"},{"location":"#thesis-proposal","text":"","title":"Thesis Proposal"},{"location":"#braco-robotico-e-humano-desempenham-tarefas-de-forma-colaborativa","text":"","title":"Bra\u00e7o Rob\u00f3tico e Humano Desempenham Tarefas de Forma Colaborativa"},{"location":"#enquadramento-e-motivacao","text":"Os bra\u00e7os rob\u00f3ticos industriais, na sua instala\u00e7\u00e3o cl\u00e1ssica e n\u00e3o colaborativa, executam as suas tarefas em espa\u00e7os nos quais est\u00e1 vedada a presen\u00e7a de humanos. Essa veda\u00e7\u00e3o pode ser f\u00edsica, atrav\u00e9s de jaulas, por exemplo, ou virtual. Por quest\u00f5es de seguran\u00e7a, tipicamente, o rob\u00f4 para se algu\u00e9m entrar dentro do espa\u00e7o de seguran\u00e7a. A Rob\u00f3tica Colaborativa representa uma nova forma de integrar os rob\u00f4s, e, em particular, os bra\u00e7os rob\u00f3ticos com capacidade de manipula\u00e7\u00e3o, em ambientes industriais. O princ\u00edpio \u00e9 fazer com que os rob\u00f4s colaborativos desempenhem as suas tarefas, de forma segura, em espa\u00e7os que s\u00e3o partilhados por humanos, e tamb\u00e9m que os rob\u00f4s colaborativos possam executar tarefas conjuntamente com humanos, colaborando para a execu\u00e7\u00e3o eficaz dessa tarefa. Avan\u00e7os recentes no hardware dos bra\u00e7os rob\u00f3ticos permitem novas funcionalidades como a execu\u00e7\u00e3o de movimentos em modo compliant ou a medi\u00e7\u00e3o de torques e for\u00e7as em v\u00e1rias juntas. \u00c9 tamb\u00e9m importante ter a capacidade de perceber as posi\u00e7\u00f5es do bra\u00e7o, humanos e outros objetos e melhorar as capacidades de intera\u00e7\u00e3o entre humano-rob\u00f4.","title":"Enquadramento e Motiva\u00e7\u00e3o"},{"location":"#objetivos-e-plano-de-trabalhos","text":"O objetivo desta disserta\u00e7\u00e3o \u00e9 o desenvolvimento de t\u00e9cnicas que potenciem a partilha de espa\u00e7o entre humanos e um bra\u00e7o rob\u00f3tico inserido numa c\u00e9lula industrial. O rob\u00f4 deve interagir com o humano atrav\u00e9s de gestos e toque. Deve ser poss\u00edvel passar objetos ou ferramentas entre o humano e o rob\u00f4, e no sentido inverso. O rob\u00f4 deve colaborar com o humano na execu\u00e7\u00e3o das tarefas e deve movimentar-se de modo a assegurar a integridade f\u00edsica do(s) humano(s) presente(s) no seu espa\u00e7o de trabalho. A c\u00e9lula industrial est\u00e1 dotada de c\u00e2maras e outros sensores, como, por exemplo, Velodyne Lidar, para melhorar a percep\u00e7\u00e3o de todos os objetos e pessoas no espa\u00e7o de trabalho. As ferramentas a desenvolver dever\u00e3o estar integradas com ROS (Robot Operating System), podendo ser considerada a utiliza\u00e7\u00e3o da vers\u00e3o ROS ou da vers\u00e3o ROS2.","title":"Objetivos e plano de trabalhos"},{"location":"#plano-de-trabalhos","text":"Levantamento do estado da arte sobre rob\u00f3tica colaborativa, intera\u00e7\u00e3o humano-rob\u00f4 e percep\u00e7\u00e3o de ambientes industriais; Desenvolvimento de t\u00e9cnicas de intera\u00e7\u00e3o com o rob\u00f4 atrav\u00e9s de gestos e toque, ou outras modalidades; Desenvolvimento de t\u00e9cnicas que permitam a transfer\u00eancia de ferramentas ou outros objetos entre rob\u00f4 e humano; Desenvolvimento de t\u00e9cnicas de planeamento de movimentos que assegurem a seguran\u00e7a das opera\u00e7\u00f5es de manipula\u00e7\u00e3o do bra\u00e7o rob\u00f3tico, mesmo na presen\u00e7a de humanos/obst\u00e1culos m\u00f3veis. Teste e valida\u00e7\u00e3o das t\u00e9cnicas desenvolvidas. Reda\u00e7\u00e3o da disserta\u00e7\u00e3o","title":"Plano de Trabalhos"},{"location":"conclusion/","text":"","title":"Conclusion"},{"location":"hand_guide/","text":"Hand Guiding Force / Torque Sensor Correction End Effector Weight Compensation Force / Torque to Robot Motion","title":"Hand Guiding"},{"location":"hand_guide/#hand-guiding","text":"","title":"Hand Guiding"},{"location":"hand_guide/#force-torque-sensor-correction","text":"","title":"Force / Torque Sensor Correction"},{"location":"hand_guide/#end-effector-weight-compensation","text":"","title":"End Effector Weight Compensation"},{"location":"hand_guide/#force-torque-to-robot-motion","text":"","title":"Force / Torque to Robot Motion"},{"location":"intro/","text":"Introduction Motivation Objectives Outline","title":"Introduction"},{"location":"intro/#introduction","text":"","title":"Introduction"},{"location":"intro/#motivation","text":"","title":"Motivation"},{"location":"intro/#objectives","text":"","title":"Objectives"},{"location":"intro/#outline","text":"","title":"Outline"},{"location":"logbook/","text":"Logbook 10/11 - Pesquisar papers (Bronze) Encontrei +30 papers sobre intera\u00e7\u00e3o de robots industriais e humanos. Guardei para futura leitura e resumo Sites de papers cient\u00edficos ResearchGate IEEEXplore Science Direct Encontrei 3 sites com recursos interessantes para o tema RIA - https://www.robotics.org/ UR - https://www.universal-robots.com/ A3 - https://www.a3automate.org/ 11/11 - Reuni\u00e3o (IRISlab) Com o Prof Nuno Lau e Bernardo Cunha Apresenta\u00e7\u00e3o do Projeto Augmanity, composi\u00e7\u00e3o do sistema, datas e entreg\u00e1veis Escrita da tese fica para o final do desenvolvimento In\u00edcio do logbook Tarefas Passagem de objeto do robot para humano Utiliza\u00e7\u00e3o de posi\u00e7oes pr\u00e9 definidas Leitura do sensor de 3 eixos do end-efector para o robot largar o objeto 16/11 - Pesquisa (Posto) Ao pesquisar sobre o sensor de for\u00e7a do end-efector (TCP), descobri que o driver oficial publica no t\u00f3pico /wrench os valores que l\u00ea do sensor 17/11 - Teste (IRISLab) Ao iniciar um novo workspace com o reposit\u00f3rio do driver oficial, o driver inicia sem problema, e publica no t\u00f3pico /wrench 3 valores de for\u00e7a e 3 valores de torque. Existe no entanto o problema de n\u00e3o consegui conectar o MoveIt ao robot, com erros variados Um deles estava relacionado com a aus\u00eancia de um ficheiro de calibra\u00e7\u00e3o interna, que ap\u00f3s o obter, resolvi o problema Ao tentar dar merge do novo driver com o reposit\u00f3rio do Eurico, os erros persistiram Ao tentar dar merge novamente em casa, consegui compilar o projeto e executar sem problemas no gazebo. Penso que \u00e9 esperado visto que os problemas est\u00e3o maioritariamente no driver do robot real Reposit\u00f3rios Importantes Eurico - https://github.com/iris-ua/iris_ur10e UR Driver - https://github.com/UniversalRobots/Universal_Robots_ROS_Driver UR Description e MoveIt (recomendado) - https://github.com/fmauch/universal_robot/tree/calibration_devel Este possui um branch interessante \"moveit\" cuja pasta ur10e_moveit_config \u00e9 mais recente que todas as outras UR Description e MoveIt (oficial) - https://github.com/ros-industrial/universal_robot Criei 3 workspaces diferentes. 1 com o driver do eurico (iris_ws). 1 com o driver oficial (ros_ws). 1 onde vou tentar dar merge dos 2 (merge_ws) 18/11 - Reuni\u00e3o (IRISLab) Ao tentar adaptar o merge_ws para os parametros do iris_ws (que funciona) reparei numa linha do ur10e_bringup.launch onde, por alguma razao, o force_torque_sensor_controller nao estava incluido na lista de controladores. Ao incluir, o driver j\u00e1 publica os valores do sensor para o t\u00f3pico /wrench. Vou prosseguir com a utiliza\u00e7\u00e3o do iris_ws, deixando a adapta\u00e7\u00e3o do merge_ws para depois. Implementa\u00e7\u00e3o do planeador STOMP no iris_ws Adapta\u00e7\u00e3o do n\u00f3 ArmControl ao ambiente (remo\u00e7\u00e3o de c\u00f3digo relativo ao iris_cork) Valores de torque do t\u00f3pico /wrench s\u00e3o cartesianos e e relativos ao tool0_controller mas os valores iniciais n\u00e3o s\u00e3o claros. O y inicia com um valor demasiado alto e a rota\u00e7\u00e3o do end-effector n\u00e3o parece impactuar esses valores. Afinal, apos reinicar o robot e ler logo a seguir os valores de /wrench, ficam todos muito pr\u00f3ximos de 0 Ap\u00f3s algum tempo a testar, \u00e9 n\u00edtido que a cada reboot do robot, os valores iniciais de for\u00e7a s\u00e3o inicializados a zero. Como era de esperar, diferentes posi\u00e7oes do gripper provocam altera\u00e7\u00e3o nos valores de for\u00e7a (os valores podem alterar-se at\u00e9 +/- 10) permanecendo nesse estado. Os valores n\u00e3o parecem ser absolutos, mas sim relativos \u00e0 posi\u00e7\u00e3o inicial em que o robot \u00e9 ligado V\u00e1rias reinicializa\u00e7\u00f5es do driver n\u00e3o provocam altera\u00e7\u00e3o nos valores de for\u00e7a Muito possivelmente, a melhor forma de utilizar os valores deste sensor, ser\u00e1 apenas utilizando a diferen\u00e7a de for\u00e7a com o tempo, pois se o gripper se mantiver est\u00e1vel, os valores variam em +/- 1 sendo que a aplica\u00e7\u00e3o de uma for\u00e7a adequada por parte do utilizador ao gripper, provoca varia\u00e7\u00e3o nos valores em +/- 15 (Newtons?) Valores de torque ainda s\u00e3o uma inc\u00f3gnita -> J\u00e1 n\u00e3o s\u00e3o uma inc\u00f3gnita. Valores de torque representam for\u00e7as circulares aplicadas ao end efector Alterar a orienta\u00e7\u00e3o do gripper faz com que os valores de for\u00e7a se alterem... Mesmo o robot estando est\u00e1tico Tarefas Recolher valores do sensor tendo em conta a varia\u00e7\u00e3o de Poses de inicializa\u00e7\u00e3o do robot V\u00e1rias poses do robot V\u00e1rias orienta\u00e7\u00f5es do gripper Com e sem um um objeto 4 bags gravados (wrench3, wrench10, all3, all10) Testes com novo n\u00f3 tests.py para criar diferentes conjuntos de posi\u00e7\u00f5es 19/11 - IRISLab \u00c0 medida que o tempo passa, o sensor de for\u00e7a vai acumulando erros e, sem mexer no robot, os valores v\u00e3o-se afastando linearmente de como s\u00e3o inicializados (0,0,0) Programa de testes em que o EE se mexe em XYZ sem alterar orienta\u00e7\u00e3o provoca for\u00e7as irrelevantes no sensor Recalibra\u00e7\u00e3o do TCP Valores actuais - {Payload: 1.77kg, CX: -5.0, CY: 0.0, CZ: 45.0} Calibra\u00e7\u00e3o 1 - {Payload: 1.67kg, CX: -3.0, CY: 0.0, CZ: 41.0} Calibra\u00e7\u00e3o 2 - {Payload: 1.84kg, CX: -1.0, CY: 1.0, CZ: 37.0} Calibra\u00e7\u00e3o 3 - {Payload: 1.84kg, CX: -5.0, CY: -5.0, CZ: 38.0} Calibra\u00e7\u00e3o 4 - {Payload: 1.73kg, CX: -3.0, CY: 2.0, CZ: 49.0} Calibra\u00e7\u00e3o 5 - {Payload: 1.69kg, CX: 10.0, CY: 0.0, CZ: 39.0 Agora com o Gripper Fechado Calibra\u00e7\u00e3o 6 - {Payload: 1.76kg, CX: -1.0, CY: -3.0, CZ: 40.0} Calibra\u00e7\u00e3o 7 - {Payload: 1.67kg, CX: -1.0, CY: 3.0, CZ: 48.0} Calibra\u00e7\u00e3o 8 - {Payload: 1.63kg, CX: 1.0, CY: -5.0, CZ: 47.0} Agora Reinicializando o Robot Calibra\u00e7\u00e3o 9 - {Payload: 1.72kg, CX: -2.0, CY: -8.0, CZ: 40.0} Calibra\u00e7\u00e3o 10 - {Payload: 1.69kg, CX: -8.0, CY: -2.0, CZ: 40.0} Ap\u00f3s v\u00e1rias tentativas de calibra\u00e7\u00e3o, decidi usar os valores atuais mas centrar o TCP em X = 0 2/12 - IRISLab Estudo dos valores de for\u00e7a do sensor, gr\u00e1ficos em screenshots -> wrench Pasta 1-wrench Movimentos simples em XYZ sem aplicar rota\u00e7\u00e3o do EE, provocam oscila\u00e7\u00f5es quando o robot se est\u00e1 a mover. Valores oscilam entre [-5, 6] Rota\u00e7\u00f5es do EE provocam maiores oscila\u00e7\u00f5es e estes valores permanecem alterados, ap\u00f3s a rota\u00e7\u00e3o. Ver screenshots TESTE - Mover 3 vezes, pi/4 graus - Mover -3*pi/4 graus - Mover 3 vezes, -pi/4 graus - Mover 3*pi/4 graus NOTA - Rota\u00e7\u00f5es positivas, EE roda no sentido hor\u00e1rio RESULTADO - A posi\u00e7\u00e3o do EE influencia a amplitude dos valores e nota-se um padr\u00e3o constante nas 3 posi\u00e7\u00f5es experimentadas Altera\u00e7\u00e3o do peso do payload TESTE - Alterar o peso do payload para 1.4kg RESULTADO - A amplitude dos valores diminuiu em X mas aumentou em Y TESTE - Alterar o peso do payload para 1kg RESULTADO - Houve uma alter\u00e7\u00e3o nos valores de X (como que uma invers\u00e3o), e a amplitude de valores em Y aumentou significativamente TESTE - Alterar o peso do payload para 2kg RESULTADO - Mais uma vez, os valores em X inverteram-se, e a amplitude de valores em Y diminuiu NOTA - O problema n\u00e3o parece estar apenas relacionado com peso mas tamb\u00e9m com o centro de gravidade Recalibrar o peso e centro de gravidade do TCP Novos valores - {Payload: 1.71kg, CX: -1.0, CY: 0.0, CZ: 41.0} RESULTADO - Exatamente o mesmo do primeiro teste de rota\u00e7\u00e3o Novos valores - {Payload: 1.79kg, CX: 3.0, CY: 2.0, CZ: 36.0} RESULTADO - Exatamente o mesmo do primeiro teste de rota\u00e7\u00e3o Testar os movimentos simples em XYZ ap\u00f3s uma rota\u00e7\u00e3o revela o esperado, ou seja, inicialmente, os valores alteram-se drasticamente na rota\u00e7\u00e3o, no entanto, durante as transla\u00e7\u00f5es, as oscila\u00e7\u00f5es s\u00e3o muito menores Altera\u00e7\u00e3o do Centro de Gravidade TESTE - Alterar para X = 0, Y = 0, Z = 0 RESULTADO - Exatamente o mesmo do primeiro teste de rota\u00e7\u00e3o TESTE - Alterar para X = 50, Y = 50, Z = 50 RESULTADO - Exatamente o mesmo do primeiro teste de rota\u00e7\u00e3o Alterar o valor do peso do payload ou qualquer componente do centro de gravidade do TCP faz com que o controlador do sensor reinicie os seus valores a zero, por menor que seja a altera\u00e7\u00e3o, qualquer que seja, provoca um reset Reposit\u00f3rio iniciado com o iris_ws -> https://github.com/fabioalves98/HumanRobotColaboration Programa wrench.py faz agora display dos valores num gr\u00e1fico em tempo real no modo live 3/12 - IRISLab Ver os resultados em tempo real n\u00e3o ajudou a obter novas conclus\u00f5es Os valores de for\u00e7a que o controlador interno do robot publica, s\u00e3o relativos ao eixo da base robot. O n\u00f3 ur_hardware_interface, antes de publicar para /wrench, multiplica estes valores pelo transform da pose do TCP para obter os valores de for\u00e7a em rela\u00e7\u00e3o ao TCP 4/12 - IRISLab Guardados 3 novos bags wrench_pushes.bag - Onde o gripper agarra num peda\u00e7o de corti\u00e7a e eu puxo em v\u00e1rias dire\u00e7\u00f5es com diferentes n\u00edveis de for\u00e7a wrench_taps.bag - Leves toques r\u00e1pidos nos lados do gripper wrench_twists.bag - Onde ao agarra no gripper o tento rodar em v\u00e1rias dire\u00e7\u00f5es para testar a sensibilidade dos valores de torque 7/12 - Posto Descobri um servi\u00e7o que reinicializa o sensor de for\u00e7a e torque (zero_ftsensor) e outro que reenvia um programa URScript ao robot (resend_robot_program), \u00fatil para quando o robot entra em protective stop ou emergency stop Encontrei Issues no Github do driver do UR10e muito parecidos com o problema Programa wrench integra os valores de /wrench em tempo real para detetar corretamente uma intera\u00e7\u00e3o com o robot Tarefas Filtar os valores de ru\u00eddo e fazer uma fun\u00e7\u00e3o de integra\u00e7\u00e3o que detete corretamente for\u00e7as e toques r\u00e1pidos Moving Average Filter - https://maker.pro/arduino/tutorial/how-to-clean-up-noisy-sensor-data-with-a-moving-average-filter Kalman Filter - ? 9/12 - Reuni\u00e3o (IRISLab) Programa wrench avalia os valores de for\u00e7a e consoante a for\u00e7a aplicada em cada eixo, abre ou fecha o gripper. Valor de for\u00e7a \u00e9 parametrizavel. No eixo X (lateral), uma for\u00e7a em qualquer dor sentidos fecha o gripper No eixo Y e Z (frontal, uma for\u00e7a no sentido do utilizador abre o gripper Continua o mesmo problema em que se o EE rodar, os valores alteram-se O driver obtem os valores de FT atraves de um cliente RTDE que comunica com um servidor presente no controlador interno do UR10e. Esse servidor publica os valores de for\u00e7a que calcula em rela\u00e7\u00e3o ao eixo do robot, e depois o driver transforma-os para a pose do TCP Para solucionar, \u00e9 poss\u00edvel usar a nova fun\u00e7\u00e3o que integra os valores e aplica um filtro de m\u00e9dia para controlar o gripper. Desta forma o controlo do gripper nao \u00e9 afetado pelas sucessivas rota\u00e7\u00f5es e movimentos do robot e acumula\u00e7\u00f5es de erro do sensor FT 17/12 - Teste (IRISLab) Nova tentativa de resolver o problema do wrench. Retirar os valores de for\u00e7a em todos os angulos possiveis, por num gr\u00e1fico, tentar descobrir um padr\u00e3o a fim de compensar o comportantomento an\u00f3malo do controlador Pasta 2-wrench Posi\u00e7oes P1 - out_of_camera P2 - P1 -> rotate 0 -pi/4 0 P3 - P1 -> rotate 0 -pi/2 P4 - P1 -> rotate 0 -3/4 0 P5 - P1 -> rotate 0 pi/4 0 P6 - P1 -> rotate 0 0 pi/4 P7 - P1 -> rotate 0 0 -pi/4 Testes Teste 1 | Posi\u00e7\u00e3o 1 | zero_ftsensor quando wrist3_joint est\u00e1 a 0 |-180 a 180 Teste 2 | Posi\u00e7\u00e3o 1 | zero_ftsensor quando wrist3_joint est\u00e1 a -180 | -180 a 180 Teste 3 | Posi\u00e7\u00e3o 1 | zero_ftsensor quando wrist3_joint est\u00e1 a 180 | -180 a 180 Fixar os eixos do gr\u00e1fico para todos os testes ficarem com os mesmos eixos Teste 4 | Posi\u00e7\u00e3o 1 | zero_ftsensor quando wrist3_joint est\u00e1 a 0 | -180 a 180 Teste 5 | Posi\u00e7\u00e3o 2 | zero_ftsensor quando wrist3_joint est\u00e1 a 0 | -180 a 180 Teste 6 | Posi\u00e7\u00e3o 3 | zero_ftsensor quando wrist3_joint est\u00e1 a 0 | -180 a 180 Teste 7 | Posi\u00e7\u00e3o 4 | zero_ftsensor quando wrist3_joint est\u00e1 a 0 | -180 a 180 Teste 8 | Posi\u00e7\u00e3o 5 | zero_ftsensor quando wrist3_joint est\u00e1 a 0 | -180 a 180 Teste 9 | Posi\u00e7\u00e3o 6 | zero_ftsensor quando wrist3_joint est\u00e1 a 0 | -180 a 180 Teste 10 | Posi\u00e7\u00e3o 7 | zero_ftsensor quando wrist3_joint est\u00e1 a 0 | -180 a 180 Inconclusivos 18/12 - Teste (IRISLab) Nova tentativa de resolver o problema do wrench. Fazer os mesmos testes anteriores mas sem o gripper attached ao robot Pasta 3-wrench Posi\u00e7\u00f5es P1 - Joints [0, -90, 0, 0, 0, 0] P2 - Joints [0, -90, 0, 0, 90, 0] P3 - Joints [0, -90, 0, 0, -90, 0] P4 - Joints [0, -90, 0, 0, -45, 0] P5 - Joints [0, -90, 0, 0, 45, 0] P6 - out_of_camera P7 - init_calibration P8 - desk_pick Novo gr\u00e1fico com valores de torque 08/01 - Desenvolvimento (BMIlhavo) Programa fit.py que dessenha 3 fun\u00e7\u00f5es seno, configuradas de maneira diferente de modo a tentar aproximar as curvas obtidas nos programas de teste do wrench.py Curvas aparentam ter proximidade com os gr\u00e1ficos do wrench.py 13/01 - Reuni\u00e3o (IRISLab) Novos testes com persistencia dos resultados em mem\u00f3ria, sem gripper Pasta F-wrench Posi\u00e7\u00f5es P1 - Joints [0, -90, 0, 0, 90, 0] P2 - Joints [0, -90, 0, 0, 45, 0] P3 - Joints [0, -90, 0, 0, 0, 0] P4 - Joints [0, -90, 0, 0, -45, 0] P5 - Joints [0, -90, 0, 0, -90, 0 M\u00e9dia e desvio padr\u00e3o das diferen\u00e7as dos resultados Mean - [ 0.41535386, 0.4073297 , 0.48555393] Std Dev - [ 0.07199976, 0.07887803, 0.09579287] To Do Verificar repetibilidade dos testes Verificar se dar resest em angulos de wrist_3 diferentes provoca os mesmos resultados Verificar o drift do sensor, tanto temporal como espacial Verificar os valores de TCP Force pelo URScript Dar fit de uma fun\u00e7\u00e3o seno nos resultados M\u00e9todo dos m\u00ednimos quadrados Criar modelo que aplique a fun\u00e7\u00e3o para corrigir a vari\u00e2ncia dos valores de for\u00e7a 01/03 - IRISLab Repetibilidade Repeti\u00e7\u00e3o dos testes para verificar repetibilidade dos resultados Pasta F-wrench (repeat) Posi\u00e7\u00f5es e diferen\u00e7a de valores comparado com os testes anteriores P1 - Joints [0, -90, 0, 0, 90, 0] Mean - [ 0.20678017, 0.49250442, 0.29758366] Std Dev - [ 0.16025934, 0.125027 , 0.21015851] P2 - Joints [0, -90, 0, 0, 45, 0] Mean - [ 0.29473815, 0.69158735, 0.89929321] Std Dev - [ 0.17148463, 0.43221503, 0.27771454] P3 - Joints [0, -90, 0, 0, 0, 0] Mean - [ 0.30978849, 0.37630247, 0.34874062] Std Dev - [ 0.18629143, 0.18554891, 0.18170008] P4 - Joints [0, -90, 0, 0, -45, 0] Mean - [ 0.13864991, 0.2199402 , 0.5447835] Std Dev - [ 0.09905205, 0.16799613, 0.25183081] P5 - Joints [0, -90, 0, 0, -90, 0] Mean - [ 0.35275194, 0.41744611, 0.24365676] Std Dev - [ 0.21623916, 0.33241225, 0.18720336] M\u00e9dia e desvio padr\u00e3o das diferen\u00e7as dos resultados Mean - [ 0.48826575, 0.48218191, 0.70701964] Std Dev - [ 0.11487946, 0.14974243, 0.16440651] Resultado - Todos os testes aparentam ser pass\u00edveis de ser repetidos e apresentar os mesmos valores M\u00e9dia e desvio padr\u00e3o do conjunto dos 10 testes Mean - [ 0.43229188, 0.47148803, 0.56602416] Std Dev - [ 0.07462753, 0.15599019, 0.10256855] Dar reset noutro s\u00edtio e sobrepor os valores Teste T6 - Posi\u00e7\u00e3o P5 - /zero_ft_sensor chamado com wrist_3 = -75 Resulta em curvas com o mesmo padr\u00e3o mas deslocadas verticalmente Utilizando o fit.py para dar plot de T5 e T6 Resultado - Se compensarmos T6 com o valor de T5 em wrist_3 = 75, obtemos T5 com pouca variabilidade de (< 0.5N) Drift Temporal Teste TD - Posi\u00e7\u00e3o P2/P3/P4 - /zero_ft_sensor chamado com wrist_3 = 0 Gravar valores durante 10 minutos sem movimento Resultado - Os valores variam linearmente com o tempo 02/03 - IRISLab Peso do Gripper - 1.336 Kg Peso do Encaixe do Gripper - 0.178 g Peso do Conjunto - 1.514 Kg Drift Posicional Teste TP - Posi\u00e7\u00e3o P1 - /zero_ft_sensor chamado com wrist_3 = 0 Mover o bra\u00e7o para uma posi\u00e7\u00e3o random - \"out_of_camera\" Aplicar 180 graus de rota\u00e7\u00e3o no wrist_3 Voltar para a posi\u00e7\u00e3o P1 Correr o teste sem dar reset no inicio do teste Resultado - Comparando com o teste default T1_P1 n\u00e3o h\u00e1 vari\u00e2ncia not\u00e1vel nos resultados Correr o teste mas dar reset no in\u00edcio do teste Resultado - Comparando com o teste default T1_P1 n\u00e3o h\u00e1 vari\u00e2ncia not\u00e1vel nos resultados Fit de uma Fun\u00e7\u00e3o Seno Aplica\u00e7\u00e3o da fun\u00e7\u00e3o curve_fit da bilbioteca scipy, com uma fun\u00e7\u00e3o custumizada seno com 4 parametros y = p1 * np.sin(np.radians(p2 * (x + p3))) + p4 Amplitude, frequencia, offset_x, offset_y Defini\u00e7\u00e3o de valores de guess iniciais Resultado - Parametros finais x - [3.59403687, 2.16328845, -56.15475734, 2.55574389] y - [1.18181371, 2.16484226, 39.16549121, -0.45171281] z - [1.96991165, 2.00442201, 41.65549264, -2.1853712 ] 03/03 - IRISLab (Reuni\u00e3o) Tentativa de corrigir os valores de for\u00e7a vindo do wrench em tempo real Problemas no geral. Poss\u00edveis causas Maneira de obter o valor do wrist_3 do robot Problema de velocidade dos t\u00f3picos Problema em acesso com exclusividade mutua aos valores no wrench.py Reuni\u00e3o - To Do Dar merge das curvas com gripper e sem gripper Fazer modelo te\u00f3rico de como o gripper se dever\u00e1 comportar em diferentes orienta\u00e7\u00f5es Parametros seriam a orienta\u00e7\u00e3o do gripper, peso e centro de gravidade Usar esse modelo te\u00f3rico, repetir os testes e melhorar o modelo com testes V\u00eddeos - https://www.youtube.com/c/EnergidTechnologies/videos 05/03 - IRISLab Repeti\u00e7\u00e3o dos teses com o Gripper attatched Pasta F-Wrench Mesmas 5 posi\u00e7\u00f5es que anteriormente Mais uma B\u00f3nus - out_of_camera Testes com valores diferentes de Payload e COV Diferetes valores de payload alteram drasticamente os valores do sensor Diferentes valores de centro de gravidade n\u00e3o alteram os valores do sensor Merge das Curvas com e sem Gripper Valores de diferen\u00e7a entre curvas originais e com gripper fazem algum sentido, mas n\u00e3o s\u00e3o suficientes para retirar Valores de diferen\u00e7a em X, fazem sentido pois a posi\u00e7\u00e3o wrist_3 = 0 tem o eixo X alinhado verticalmente, ou seja, quando ha o zerto_ft_sensor(), todo o peso do gripper est\u00e1 sobre esse eixo, e h\u00e1 medida que rodamos, esse peso vai passando para o eixo Y, logo \u00e9 normal que o valor de X aumente A parte estranha \u00e9 que o valor de Y n\u00e3o se altera em todo o teste Ainda mais estranho, \u00e9 que o valor de Z se altera Uma poss\u00edvel explica\u00e7\u00e3o \u00e9 que estes 2 testes diferem no valor configurado de payload Quando foram medidos sem gripper - Payload era 0Kg Quando foram medidos com gripper - Payload era 1.77Kg Resultado - Inconclusivo 06/03 - Casa Refactor do workspace com os pacotes iris_sami e iris_ur10e Refactor de c\u00f3digo com helper functions 07/03 - Casa Paper - Human\u2013robot interaction in industrial collaborative robotics: a literature review of the decade 08/03 - IRISLab Testes com diferentes valores de payload sem Gripper Pasta F-Wrench Teste Payload | Posi\u00e7\u00e3o 1 | Payload de x Kg TP1_0Kg Igual ao teste default TP1_0.2Kg e TP1_1Kg Exatamente igual a TP1_0Kg TP2_0Kg Igual ao teste default TP2_0.2kg e TP2_1Kg Apresentam diferen\u00e7as significativas em rela\u00e7\u00e3o a TP2 que fazem todo o sentido Repeti\u00e7\u00e3o para a P3 com resultados analogos a P1, ou seja, as diferen\u00e7as foram ainda maiores Resutlado - Ap\u00f3s verifica\u00e7\u00e3o dos resultados corrigidos faz todo o sentido Ao adicionarmos valores falsos de payload, eles v\u00e3o ser retratados nas curvas Teste com Payload 0 com e sem gripper (sem dar reset entre os testes) Posi\u00e7\u00e3o B - [0, -90, -90, 0, 0, 0] Teste Payload | Posi\u00e7\u00e3o B | Payload de x Kg TPB_0Kg Igual ao teste default TPBG_0Kg Diferen\u00e7as extremas devido ao acopulamento do gripper, os valores fazen sentido, no geral For\u00e7a com que o gripper \u00e9 acopulado ao end effector interfere com os valores de Z Restulado - Compensas\u00e3o dos valores obtidos com a acopula\u00e7\u00e3o do gripper demonstram curvas sinosoidais realistas e cujos valores fazem sentido Obten\u00e7\u00e3o do peso do gripper fazendo primeiro Compensas\u00e3o da component Z com a sua m\u00e9dia A raiz dos quadrados das 3 compoentes Obtemos a cada posi\u00e7\u00e3o de wrist_3 a magnitude do vector forca Fazendo a m\u00e9dia obteve-se o valor de 15.13 N O peso do conjunto \u00e9 de 1.514 Kg Testes com diferentes valores de payload com Gripper Obter o melhor valor de peso para inserir no payload Posi\u00e7\u00e3o B - [0, -90, -90, 0, 0, 0] Teste Payload | Posi\u00e7\u00e3o B | Payload de x Kg Testados payloads de 1.2kg a 1.8Kg com intervalos de 100g Objetivo \u00e9 ver qual payload \u00e9 que produz a curva mais aproximada \u00e0 curva de corre\u00e7\u00e3o Resultado - Nenhuma curva de aproxima completamente mas as mais pr\u00f3ximas em termos de m\u00e9dia e desvio padr\u00e3o s\u00e3o 1.5Kg e 1.6kg que \u00e9 aproximadamente o peso do gripper Os desvios poder\u00e3o estar a ser causados pelo COG 09/03 - IRISLab Testes com diferentes valores de COG com gripper Testar impacto de COG nas curvas obtidas Teste COG | Posi\u00e7\u00e3o [1, 2, 3] Center of Gravity com 0mm em todas as componentes Center of Gravity com 100mm em todas as componentes Center of Gravity com 200mm em todas as componentes Resultado - Parece haver alguma varia\u00e7\u00e3o mas nem suficientemente grande que necessite de ser corrigida, nem apresenta um padr\u00e3o definido Testes com Gripper em diferentes posi\u00e7\u00f5es e payloads Testar o efeito de diferentes valores em diferentes posi\u00e7\u00f5es Teste Payload | Posi\u00e7\u00e3o [1, 2, 3, 4, 5] | Payload [0, 1.5, 3] Resultado Tanto na posi\u00e7\u00e3o 1 como 5 as curvas n\u00e3o apresentaram diferen\u00e7as cosoante a altera\u00e7\u00e3o do payload, como era esperado Nas posi\u00e7\u00f5es 2, 3 e 4 as curvas apresntam diferen\u00e7as nas magnitudes esperadas No entanto, quando corrigidas em 1.5kg (peso real do gripper) apresentam algumas oscila\u00e7\u00f5es que ter\u00e3o que ser corrigidas 15/03 - IRISLab Obter melhor peso do Gripper com v\u00e1rias posi\u00e7\u00f5es e payloads Voltar a tentar testar o melhor valor de payload introduzido no robot para ver se \u00e9 poss\u00edvel obter uma \u00fanica curva em v\u00e1rias posi\u00e7\u00f5es A curva do gripper n\u00e3o tem que ser necessariamente igual \u00e0 curva sem gripper, no entanto, n\u00e3o pode mudar consoante a posi\u00e7\u00e3o Teste Gripper | Posi\u00e7\u00e3o 1 [1, 2, 3, 4, 5] | Payloads [1.4, 1.5, 1.6] Resultado Os testes s\u00e3o repet\u00edveis - caso de exemplo 1.5kg Estas diferen\u00e7as no payload s\u00e3o representadas nos resultados, sendo que 1.5Kg \u00e9 o valor que mais se aproximo \u00e0 curva default (sem gripper) 16/03 - IRISLab Conjunto extenso de poses de forma abrangir o maior n\u00famero de orienta\u00e7\u00f5es Array de angulos - [-180, -135, -90, -45, 0, 45, 90, 135, 180] 2 ciclos de itera\u00e7\u00e3o por este array e atribu\u00e7\u00e3o de valor de junta a wrist_1 e wrist_2 Total de 70 posi\u00e7\u00f5es Modelo te\u00f3rico do comportamento do sensor de for\u00e7a quando o gripper est\u00e1 acopulado 3 vetores com a orienta\u00e7\u00e3o do Sensor 1 vetor com magnitude e orienta\u00e7\u00e3o da gravidade Calcular teoricamente cada componente do vetor gravidade em cada 1 dos 3 eixos do sensor FT 17/03 - IRISLab Conclus\u00e3o do modelo te\u00f3rico do sensor Utiliza\u00e7\u00e3o do produto interno dos vetores normalizados anteriormente definidos para calculo do valor da for\u00e7a em cada componente 18/03 - IRISLab Teste de COG no robot real Com uma tabua de um metro acopulada ao gripper numa posi\u00e7\u00e3o horizontal, colocar em ambas as extremidades um peso de ~1Kg para ver se a for\u00e7a sentida pelo sensor \u00e9 a mesma Apesar de n\u00e3o ser exatamente a mesma, as diferen\u00e7as n\u00e3o sao significativas nem apresentam um padr\u00e3o Obviamente o torque sentido pelo sensor \u00e9 inverso quando colocamos o objeto do lado contr\u00e1rio da t\u00e1bua Teste de Corre\u00e7\u00e3o do Gripper Em cada 1 das 70 posi\u00e7\u00f5es de writs_1 e wrist_2 fazer o wrist_3 girar em 360 e obter os resultados obtidos com o modelo te\u00f3rico Nas mesmas 70 posi\u00e7\u00f5es obter os resultados obter os resultados com o robot real com gripper e um payload de 1.5Kg Fazer um merge e criar um modelo de corre\u00e7\u00e3o, sendo que em cada posi\u00e7\u00e3o do robot real, o valor de for\u00e7a deve ser 0 19/03 - Reuni\u00e3o Continuar 23/03 - IRISLab Teste Corre\u00e7\u00e3o do Sensor FT Pasta F-Wrench 70 posi\u00e7\u00f5es reduzidas para 57 por causa de duplicados (180 = -180) e posi\u00e7\u00f5es imposs\u00edveis de posicionar o robot (colis\u00f5es) Teste Correct | Wrist_1 {0 - 135, 45} | Wrist_2 {0 - 135, 45} TCx_w1_w2 Teste das 57 posi\u00e7\u00f5es sem gripper e Payload 0kg Resultado - Maioria destes testes inutiliz\u00e1veis devido a uma atenua\u00e7\u00e3o dos valores das curvas por motivos desconhecidos Alguns testes com gripper com valores inutiliz\u00e1veis devido \u00e0 press\u00e3o feita pelo cabo do gripper nas posi\u00e7\u00f5es mais extremas 24/03 - IRISLab A raz\u00e3o pela qual os testes anteriores estavam a apresentar uma atenua\u00e7\u00e3o nos valores das curvas devese ao facto da fila que guardava os valores de for\u00e7a estar a aumentar de tamanho, para o sobro a cada teste Teste Corre\u00e7\u00e3o Gripper (Repeat) Pasta F-Wrench 70 posi\u00e7\u00f5es reduzidas para 57 por causa de duplicados (180 = -180) e posi\u00e7\u00f5es imposs\u00edveis de posicionar o robot (colis\u00f5es) Teste Correct | Wrist_1 {0 - 135, 45} | Wrist_2 {0 - 135, 45} TCx_w1_w2 Teste das 57 posi\u00e7\u00f5es sem gripper e Payload 0kg TCG_w1_w1 Teste das 57 posi\u00e7\u00f5es com gripper e Payload 1.5kg (sem cabo) Resultado Testes sem gripper tem diverg\u00eancias muito pequenas entre si, sendo poss\u00edvel extrair uma curva m\u00e9dia de todos os testes sendo que o m\u00e1ximo de erro que poder\u00e1 existir ser\u00e1 de 1.5N Tests com gripper apresentam diverg\u00eancias entre si muito maiores, sendo que para utilizar estes dados num modelo de corre\u00e7\u00e3o ter\u00edamos que adicionar a orienta\u00e7\u00e3o do gripper 25/03 - IRISLab Modelo de Corre\u00e7\u00e3o do Sensor FT Retirar a m\u00e9dia dos testes sem gripper Corrigir os testes com gripper com a curva m\u00e9dia dos testes sem gripper e guardar os valores resultantes numa matriz Utilizar esses valores para corrigir o sensor tendo em conta que a orienta\u00e7\u00e3o do end effector tem que entrar na equa\u00e7\u00e3o Bags de Core\u00e7\u00e3o com e sem gripper correct_no_gripper_px.bag - 5 bags sem gripper nas 5 posi\u00e7\u00f5es deafult correct_gripper_px.bag - 5 bags com gripper nas 5 posi\u00e7\u00f5es default Em cada bag o robot posiciona-se na posi\u00e7\u00e3o indicada e roda o wrist_3 em 360 Erro - bags apenas gravaram /wrench e n\u00e3o /joint_states - Inutiliz\u00e1vel Setup Kinect para dete\u00e7\u00e3o de gestos http://wiki.ros.org/mit-ros-pkg/KinectDemos/HandDetection 26/03 - IRISLab Pesquisa relativa a controlo por gestos Muita utiliza\u00e7\u00e3o de leap motion controllers Kinect muito utilizada para gestos com o corpo todo Melhoramento da gera\u00e7\u00e3o de v\u00e1rias posi\u00e7\u00f5es para o end effector Cada valor de wrist_1 tem agora uma cor associada para ser mais facil fazer a distin\u00e7\u00e3o Controlo do Gripper atrav\u00e9s de For\u00e7a Controlo simples por peso - Funciona Controlo por eixo - Funciona For\u00e7a no X fecha For\u00e7a no Y abre Controlo quando lida com objetos - Funciona +/- Vari\u00e1vel est\u00e1 a agarrar algo? Pois apenas o controlo por for\u00e7a ns eixos fica desiquilibrado quando o robot est\u00e1 a agarrar algo Quando est\u00e1 a agarrar algo, a maneira de abrir o gripper tem que ser diferente Quando mede uma for\u00e7a no sentido contr\u00e1rio \u00e0 orienta\u00e7\u00e3o do gripper - Funciona Quando mede um peso pr\u00f3ximo de zero - Funciona +/- (objetos mais pesados) Problema de quando pega em objetos mais leves Problema do utilizador fazer uma for\u00e7a sobre o objeto que n\u00e3o fa\u00e7a o valor de peso passar pelo threshold Problema de quando dar reset ao sensor Periodicamente quando for observ\u00e1vel que nada est\u00e1 a interagir com o robot, e que n\u00e3o tem nenhum objeto agarrado 30/03 - IRISLab Modelo de Corre\u00e7\u00e3o do Sensor FT Necessidade de uma matriz que relacione os valores das v\u00e1rias posi\u00e7\u00f5es do end effector Cada teste apenas d\u00e1 os valores de corre\u00e7\u00e3o relativos \u00e0 posi\u00e7\u00e3o da junta wrist_3 Para criar um modelo que possa corrigir os valores em qualquer orienta\u00e7\u00e3o \u00e9 preciso algo que relacione as orienta\u00e7\u00f5es TCG_correct Teste das 57 posi\u00e7\u00f5es em que a cada itera\u00e7\u00e3o o robot \u00e9 posicionado numa posi\u00e7\u00e3o default [0, -90, 0, 0, 0, 0] \u00c9 feito o zero_ft_sensor() O robot move-se para a dada posi\u00e7\u00e3o e o valor de for\u00e7a \u00e9 medido Resultado - \u00c9 not\u00e1vel a diferen\u00e7a de valores de for\u00e7a que existe entre a posi\u00e7\u00e3o default e cada uma das posi\u00e7\u00f5es, e estas diferen\u00e7as teram que ser contabilizadas no modelo de corre\u00e7\u00e3o 31/03 - IRISLab Controlo por gestos Segmenta\u00e7\u00e3o da point cloud vinda da kinect utilizando primeiro um cropbox, facilitado por uma bounding box, em que apenas se visualiza a mesa Utiliza\u00e7\u00e3o de Euclidean Clustering para segmentar a nova cloud, obtendo apenas 2 clusters que correspondem \u00e0s m\u00e3os / bra\u00e7os viewer.cpp 05/04 - IRISLab Modelo de Corre\u00e7\u00e3o do Sensor FT Incluir a fun\u00e7\u00e3o de reset Utilizar numa fase inicial a m\u00e9dia das curvas com gripper Cria\u00e7\u00e3o de um conjunto de vetores correspondentes a cada uma das 56 posi\u00e7\u00f5es para compara\u00e7\u00e3o com a orienta\u00e7\u00e3o corrente do EE VERIFICAR TESTES DAS 56 POSI\u00c7\u00d5ES COM GRIPPER E VERIFICAR POSS\u00cdVEIS ERROS Divis\u00e3o do wrench.py em filter.py (filtro de m\u00e9dia com janela de 30 valores) e record.py (programa que move o wrist_3 de -180 a 180 e guarda os valores do sensor FT) 06/04 - IRISLab Testes nas 56 posi\u00e7\u00f5es com Gripper e Payload 0 Comparar com os testes \"sem gripper\" e \"com gripper e payload 1.5\" para tentar chegar a uma conclus\u00e3o Melhoramento do programa record.py para garantir que os valores de for\u00e7a s\u00e3o corretamente gravados em cada posi\u00e7\u00e3o do wrist_3 07/04 - IRISLab Modelo de Corre\u00e7\u00e3o do Sensor FT Seja qual for o payload, pode-se considerar como curvas de corre\u00e7\u00e3o as curvas obtidas em testes onde o EE est\u00e1 verticalmente alinhado com o ambiente, ou seja, ao rodar o wrist_3, nenhuma for\u00e7a dever\u00e1 ser exercida sobre os 3 eixos XYZ em qualquer posi\u00e7\u00e0o de wrist_3 Curva de corre\u00e7\u00e3o feita atrav\u00e9s das posi\u00e7\u00f5es de indices 2, 6, 34 e 38 (Posi\u00e7\u00f5es onde o EE est\u00e1 verticalmente orientado) Grava\u00e7\u00e3o de testes com o modelo te\u00f3rico para compara\u00e7\u00e3o com os testes reais Neste momento exitem 4 tipos de curvas Curva de corre\u00e7\u00e3o posicional do Wrist3 (proveniente da m\u00e9dia das curvas das posi\u00e7\u00f5es de indices 2, 6, 34, 38) Curva de teste das 56 posi\u00e7\u00f5es com gripper e Payload 1.5Kg Curva de teste das 56 posi\u00e7\u00f5es com gripper e Payload 0Kg Curva de teste das 56 posi\u00e7\u00f5es provenientes do modelo te\u00f3rico Implementa\u00e7\u00e3o da fun\u00e7\u00e3o reset com o modelo de corre\u00e7\u00e3o 12/04 - IRISLab GUI em GTK para os servi\u00e7os do iris_sami 13/04 - IRISLab Modelo de Correc\u00e7\u00e3o do Sensor FT Fazendo a comprara\u00e7\u00e3o entre as curvas do teste te\u00f3rico com as curvas com payload 0, vemos que existe um padr\u00e3o entre as diferen\u00e7as do 2 testes Em X, se diminuirmos a amplitude do modelo te\u00f3rico em +/- 10%, aproximamos os modelo te\u00f3rico aos valores reais Em Y, se aumentarmos a amplitude do modelo te\u00f3rico em +/- 10% aproximamos o model te\u00f3rico aos valores reais Em Z, as diferen\u00e7as s\u00e3o causadas por outros fatores, pois o modelo te\u00f3rico, nos testes executados \u00e9 sempre 0 Necessita de outro tipo de corre\u00e7\u00e3o - tamb\u00e9m divido \u00e0 for\u00e7a com que \u00e9 acopulado o gripper ao EE Modelo completamente implementado no programa correct.py Corrige possicionalemnte com o angulo do wrist_3 Corrige orientacionalmente com o modelo te\u00f3rico Fun\u00e7\u00e3o de reset implementada nas 2 fases Corre\u00e7\u00f5es finais ao Modelo Corrigir modelo te\u00f3rico com os resultados obtidos Obter um valor (os tais +/- 10%) para corrigir o modelo te\u00f3rico Testes inicias com simples m\u00e9dias das diferen\u00e7as X = 0.846 e Y = 1.115 Possibilidade de obter melhores resultados com metodo dos m\u00ednimos quadrados Corrigir o eixo Z Fazer um test onde se fa\u00e7a variar o EE em torno de X ou Y de forma a obter os valores reais de Z Comparar com o modelo te\u00f3rico Obter o offset criado pela for\u00e7a com que se apertou o gripper Obter o desvio de amplitude provavelmente existente (tal como X e Y) Corrigir o drift 15/04 - IRISLab Modelo de Corre\u00e7\u00e3o do Sensor FT Antes de aplicar os fatores de corre\u00e7\u00e3o Mean Mean - [ 1.30804571 1.50272948 1.576232 ] Mean Std - [ 0.34988912 0.50012359 0.46279643] Mean Max - [ 2.24789183 2.51883549 3.06942575] Std Mean - [ 0.81536524 0.93259604 0.99550626] Std Std - [ 0.2548648 0.31685171 0.33100798] Std Max - [ 1.41419107 1.48037816 1.6792048 ] Max Mean - [ 2.92629354 3.01282345 3.47414803] Max Std - [ 0.86005843 0.99741032 0.9491934 ] Max Max - [ 4.6716544 4.6230199 5.58771009] Necess\u00e1rio fazer mais testes para corrigir Z Z parece ser afetado diretamente por X Utilizando o mesmo fator de corre\u00e7\u00e3o que em X ( -0.154 ) Ap\u00f3s aplicar o fator de corre\u00e7\u00e3o em XYZ Mean Mean - [ 0.6251545 0.59968417 0.61334835] Mean Std - [ 0.30244126 0.32259647 0.26306484] Mean Max - [ 1.5099673 1.38590574 1.27972879] Std Mean - [ 0.33315744 0.24697093 0.32907034] Std Std - [ 0.08915038 0.09833696 0.10477162] Std Max - [ 0.75 0.75 0.67033111] Max Mean - [ 1.52328022 1.1413761 1.48248086] Max Std - [ 0.41916193 0.39568526 0.40593537] Max Max - [ 2.56008408 2.00279845 2.24928167] Z tamb\u00e9m \u00e9 afetado por um fator proporcional ao Nevess\u00e1rio fazer mais testes isoladamente ao eixo Z para o encontrar 16/04 - Reuni\u00e3o Modelo de Corrre\u00e7\u00e3o do Sensor FT Testes isolados ao eixo Z Fixar o wrist_3 numa posi\u00e7\u00e3o e fazer rodar o wrist_2 sobre um dos eixos Y ou X Resultado - Fator de corre\u00e7\u00e3o de Z = 1.230 Todos os fatores t\u00eam que ser melhorados com o metodo dos quadrados minimos \u00c9 necess\u00e1rio criar um conjunto de testes de treino, onde se iram retirar os fatores de corre\u00e7\u00e3o e um cojunto de testes de valida\u00e7\u00e3o onde os parametros possam ser testados Os fatores de corre\u00e7\u00e3o devem ser referentes tanto aos exos isolados como entre eixos (XZ ou YZ) At\u00e9 agora os fatores de corre\u00e7\u00e3o obtidos com m\u00e9dias de diferen\u00e7as retiradas das observa\u00e7\u00f5es s\u00e3o theory[:,z] += theory[:,x] * 0.154 theory[:,x] = theory[:,x] * 0.846 theory[:,y] = theory[:,y] * 1.115 theory[:,z] = theory[:,z] * 1.230 Controlo do Gripper atrav\u00e9s de For\u00e7as Cria\u00e7\u00e3o do vetor peso para atribuir a\u00e7oes ao gripper beaseadas nesse vetor Tarefas Controlo do Robot pelos movimentos de for\u00e7a Fazer com que quando o robot pegue numa pe\u00e7a, isole o peso dela, para que as for\u00e7as sentidas sejam utilizadas para controlar o seu movimento Real time motion planning 19/04 - IRISLab Refactor do modelo te\u00f3rico Controlo do Gripper atrav\u00e9s de For\u00e7as Utiliza\u00e7\u00e3o do vetor peso para que em conjunto com o vetor gravidade controlar a a\u00e7ao do gripper largar um objeto 20/04 - IRISLab Controlo do Robot atrav\u00e9s de For\u00e7as Direct communication with robot RTDE - https://www.universal-robots.com/articles/ur/interface-communication/real-time-data-exchange-rtde-guide/ URScript through socket - https://www.zacobria.com/universal-robots-zacobria-forum-hints-tips-how-to/script-via-socket-connection/ ur_rtde - https://sdurobotics.gitlab.io/ur_rtde/ Inverse Kinematics MovIt - http://docs.ros.org/en/melodic/api/moveit_tutorials/html/doc/robot_model_and_robot_state/robot_model_and_robot_state_tutorial.html Jacobian - https://www.rosroboticslearning.com/jacobian#:~:text=Jacobian%20is%20Matrix%20in%20robotics,(%20)%20of%20a%20robot%20manipulator.&text=Each%20column%20in%20the%20Jacobian,variation%20in%20each%20joint%20velocity Orocos KDL - https://www.orocos.org/wiki/orocos/kdl-wiki.html 21/04 - IRISLab Jacobian Theory Introduction to jacobian matrix Move it robot state, ik and jacobian tutorial made Start experimenting with movements in simulated ur10e (gazebo). Problems Gazebo s\u00f3 publica o estado do robot a 50Hz, ou seja, o ciclo de calculo de juntas do robot apenas pode correr num m\u00e1ximo de 50Hz Gazebo apenas aceita controlo de movimento atrav\u00e9s de valores de juntas, ou seja, requer o moveit para enviar valores de juntas -> mais lento Enviar movimento sincronamente faz com que o movimento do robot seja aos solavancos, pois, entre cada movimento h\u00e1 o tempo de calculo do proximo Enviar movimentos assincronamente funciona mas \u00e9 necess\u00e1rio encontrar a frequencia certa/\u00f3tima para enviar os movimentos, senao o robot \"encrava\" 22/04 - IRISLab Jacobian Simulation Envio de valores de juntas asincronamente ao robot atrav\u00e9s do moveit Maioria dos movimentos s\u00e3o flu\u00eddos mas h\u00e1 certas posi\u00e7\u00f5es onde o robot \"falha\" em calcular a trajetoria Ou por exceder o limite das juntas Ou por exceder o limite de alcance Ou por nao conseguir mesmo se mover nessa dada dire\u00e7\u00e3o H\u00e1 a necessidade de controlar as juntas do robot por velocidade em ves de por posi\u00e7\u00e3o 23/04 - IRISLab Jacobian Real UR10e O controlador funciona um pouco melhor pois os valores das juntas s\u00e3o publicados a 500Hz Ainda h\u00e0 alguns solavancos, mas s\u00e3o muito suaves Controlador integrado com o peso calculado para que o robot se mova na dire\u00e7\u00e3o que est\u00e1 a ser empurrado Resultados positivos Apenas h\u00e1 numa diferen\u00e7a na velocidade com que o EE se move dependendo da for\u00e7a que esta a ser execida e da sua posi\u00e7\u00e3o Pode ser resolvido efetuando o controlo das juntas por velocidade 26/04 - IRISLab URScript and RTDE Interfaces Envio de instrucoes em URScript para o Robot atrav\u00e9s de sockets pela interface Real-Time 30003 Tentativa de utiliza\u00e7\u00e3o do pacote pip python-urx mas \u00e9 prefer\u00edvel enviar os comandos manualmente Robot recebe e executa bem as intru\u00e7\u00f5es Falta testar a velocidade com que se consegue interagir com o robot Utiliza\u00e7\u00e3o da bilblioteca C++ ur_rtde para interagir com o robot Bilbioteca muito completa com muitas funcionalidades No entanto o robot apenas suporta uma liga\u00e7\u00e3o \u00e0 porta 30004 simultaneamente o que significa que o driver n\u00e3o pode estar ligado, pois este tambem usa a interface RTDE 27/04 - IRISLab URDriver mais recente Experimenta\u00e7\u00e3o da versao mais recente do ur_robot_driver que contem controladores de velocidade Tanto controladores poderosos em PID como os de posi\u00e7\u00e3o, tal como um controlador direto de velocidade das juntas do robot 28/04 - IRISLab URSim em Virtual Machine Simulador oficial do UR10e que providencia todas as interfaces e funcionalidades do robot real (excepto controlos por for\u00e7a) Aceita comandos URScript Boa plataforma para testes de intera\u00e7\u00e3o com o robot 30/04 - Reuni\u00e3o Jacobian Weight Real UR10e Testes com v\u00e1rios parametros de controlo assincrono da posi\u00e7\u00e3o do robot Comportamento actual \u00e9 aceit\u00e1vel na medida em que as trajetorias calculadas s\u00e3o precisas No entanto existe delay, a velocidade \u00e9 muito lenta, e \u00e9 necess\u00e1rio ser adaptada \u00e0 for\u00e7a que se faz (quanto mais for\u00e7a, mais r\u00e1pido) Necess\u00e1rio incorporar movimentos rotacionais utilizado o torque Multiple Control Interfaces Reuni\u00e3o Necessidade de implementar controlador com velocidades de juntas Implementar movimentos angulares com os valores de torque Fazer o robot pegar em algo e depois move-lo com a for\u00e7a Dar reset no peso quando o robot pega em algo (dar um X tempo de calibra\u00e7\u00e3o) Implementar double-tap Tentar distinguir entre mover o EE e pegar numa pe\u00e7a (rela\u00e7\u00e3o torque / for\u00e7a) 05/05 - IRISLab Movimentos angulares com os valores de torque Tentativa de traduzir valores de torque sentido no sensor FT (tool0) em rota\u00e7\u00f5es globais (world) Cria\u00e7\u00e3o de um TF (torque) que traduz uma rota\u00e7\u00e3o do tool0 no eixo do torque sentido no sensor Obter a diferen\u00e7a de rota\u00e7\u00e3o dos 2 transforms e usar essa rota\u00e7\u00e3o Problema - Apenas consegui obter a rota\u00e7\u00e3o do TF \"torque\" em rela\u00e7\u00e3o ao TF \"original\" https://answers.ros.org/question/42289/difference-between-two-rigid-body-transformations/ 10/05 - IRISLab Movimentos angulares com os valores de torque Consegui obter a rota\u00e7\u00e3o global dos 2 TFs Foi necess\u00e1rio fazer a multiplica\u00e7\u00e3o dos TFs utilizando os seus inversos, para que assim o resultado seja em rela\u00e7\u00e3o ao world Ou seja Rot = Inv(Inv(TFtq)) * Inv(TFft) = TFtq * Inv(TFft) Para mais info -> torque_to_angvel.cpp 11/05 - IRISLab Refactor da disposi\u00e7\u00e3o de todos os n\u00f3s Cria\u00e7\u00e3o de n\u00f3s especificos para velocidades lineares e angulares Cria\u00e7\u00e3o de fatores para traduzir for\u00e7a / torque em velocidade 13/05 - Reuni\u00e3o Continuar 17/05 - IRISLab Controlar as juntas por Velocidade Comandos URScript por TCP para a porta 30003 Comando speedj n\u00e3o apresenta bom funcionamento, cada vez que se envia um comando novo, o anterior para abruptamente Bilioteca UR_RTDE Comandos de velocidade funcionam corretamente e \u00e0 frequencia de 500Hz N\u00e3o \u00e9 poss\u00edvel utilizar esta bilbioteca em paralelo com o driver ROS Novo driver ROS Controlador de velocidade de juntas aparenta funcionar bem Apenas testado em URSim 18/05 - IRISLab Controlar as juntar por Velocidade Comandos URScript por TCP para a porta 30003 Nenhuma combina\u00e7\u00e3o de parametros de speedj funcionou corretamente O problema sendo que a cada novo comando urscript enviado, o anterior para abruptamente Teste com servoj que seria o comando apropriado para movimentos continuos / RT tambem nao deu resultados O robot claramente movia-se aos solavancos No entanto a interface real-time pode ser util na prespectiva de read-only para um programa de monitorament A porta 30003 esta ativa e envia informa\u00e7\u00e3o a 500Hz independentemente do modo de opera\u00e7\u00e3o do robot Biblioteca UR_RTDE Movimentos suaves e continuos a 500Hz Continua a nao haver a possibilidade de utiliza\u00e7\u00e3o em paralelo com o driver Possibilidade de utiliza\u00e7\u00e3o em Remote Control ou atravez do urcap de external control Necessidade de ser compilada manualmente para obter a vers\u00e3o mais recente Novo driver ROS Testado no robot real com a utiliza\u00e7\u00e3o \"obrigatoria\" do external_control.urcap Movimentos suaves, no entanto aparentam ausencia de controlador pois o robot, assim que lhe \u00e9 enviado um comando de velocidade, aparenta ganhar essa velocidade instantaneamente ao inves de progressivamente Tarefas Comparar UR_RTDE com o novo driver ROS a n\u00edvel de Suavidade das trajet\u00f3rias Estabilidade Delay no envio de comandos Isolar todo o sistema o mais poss\u00edvel do driver / moveit Fechar o sistema mesmo com o controlador em posi\u00e7\u00e3o utilizando o moveit 19/05 - IRISLab Sistema Fechado utilizando controlo de Posi\u00e7\u00e3o pelo MoveIt Calculo de velocidades funciona bem (jacobian) Controlador posicional moveit funciona bem se for aplicada uma for\u00e7a constante Funciona mal ao parar, pois para abruptmanete devido aos limites superiores e inferiores de for\u00e7a Funciona muito mal quando \u00e9 aplicada uma for\u00e7a baixa e constante, pois estando perto dos limites definidos, o controlo fica a oscilar entre 0 e o limite Outra raz\u00e3o, \u00e9 que para calcular um novo valor de juntas, \u00e9 necess\u00e1rio o valor presente, e n\u00e3o h\u00e1 possibilidade de saber a precis\u00e3o com que esse valor \u00e9 obtido Solu\u00e7\u00e3o Suavizar os comandos de velocidade (controlador a s\u00e9rio ou um filtro de m\u00e9dia) Controlar o robot diretamente por velocidade Ou pela interface RTDE diretamente Ou com o driver novo que tem controladores de velocidade Novo Driver Cria\u00e7\u00e3o de um ws novo onde dou merge de todas as funcionalidades com a vers\u00e3o mais recente do driver ROS do UR10e que j\u00e1 implementa controladores de velocidade At\u00e9 agora, tanto o moveit, como iris_sami e controlo por velocidade aparenta funcionar Falta testar todos o iris_cobot 20/05 - IRISLab / Reuni\u00e3o Controlo por Velocidade no Driver novo O controlador scaled_vel_joint_traj_controller nao funciona como esperado Ele nao envia um conjunto de velocidades \u00e0s juntas Ele recebe uma trajetoria contendo posicoes e velocidades e assim, controla o robot https://forum.universal-robots.com/t/ur5-constant-motion/14305 Programa scaled_vel_controller que cria trajetorias e as envia para o robot baseado no exemplo do ur_modern_driver https://github.com/ros-industrial/ur_modern_driver/blob/master/test_move.py O mais prov\u00e1vel \u00e9 vir a usar o joint_group_vel_controller Utiliza\u00e7\u00e3o do joint_vel_group_controller para enviar os valores de velocidade \u00e0s juntas Utiliza\u00e7\u00e3o de um filtro de m\u00e9dia com uma sliding window de 50 Movimentos lineares muito suaves e requerem pouca for\u00e7a Movimetos rotacionais apresentam muitas oscila\u00e7\u00f5es e a dada altura o robot gaha um comportamento de feedback em que se nao largarmos o gripper ele aumenta e fica \"agressivo\" Necessidade de tornar este controlador mais complexo (pid ou um filtro diferente) 26/05 - IRISLab Forks do Novo Driver e Descri\u00e7\u00e3o Descri\u00e7\u00e3o - https://github.com/fabioalves98/universal_robot/tree/calibration_devel Driver - https://github.com/fabioalves98/Universal_Robots_ROS_Driver Pequenas altera\u00e7\u00f5es aos pacotes para utiliza,\u00e3o com o UR10e do iries Teste de movimentos com objetos pesados Testes com pesos de 1Kg e 2Kg e payload 0 Kg definido da dashboard Movimentos com o peso de 1Kg funcionam perfeitamente Movimentos com o peso de 2Kg funcionam bem, mas alguma trajet\u00f3rias, apresentam solavancos... Provavelment devido ao calculo dos movimentos feito pelo robot nao acontar com o novo peso 28/05 - IRISLab Dete\u00e7\u00e3o de Double tap no gripper Integra\u00e7\u00e3o dos valores de for\u00e7a provenientes diretamente do /wrench Avalia\u00e7\u00e3o dos valores e escolha dos melhores parametros que permitam identificar um toque r\u00e1pido e distinguir de um toque normal Valor de diferen\u00e7\u00e3o m\u00ednima de 5N Distanca temporal minima entre toques - 100ms Distancia temporal maxima entre toques - 400ms Quando o n\u00f3 double_tap deteta um double tap, chama o servi\u00e7o de gripper_toggle 01/06 - IRISLab Review 02/06 - IRISLab M\u00e1quina de estados do Gripper Modo de intera\u00e7\u00e3o com o bra\u00e7o em que num estado inicial ele se move consoante as for\u00e7as sentidas, mas ap\u00f3s uma ac\u00e3o de double tap, o gripper fecha-se, o programa calcula o peso do objeto agarrado, compensa esse peso, e permite ao utilizador mover o bra\u00e7o com o objeto acopulado, exercendo as mesmas for\u00e7as de anteriormente M\u00e1quina de estado inicial funcional, no entanto existem solavancos nas transi\u00e7\u00f5es de estados Necessidade de uma maquina de estado geral que controla os n\u00f3s de movimento, para que eles possam ser parados / resumidos entre as transi\u00e7\u00f5es de estado Necessidade de compensar os valores de torque 07/06 - IRISLab Teste 56 posi\u00e7\u00f5es Necessidade de gravar os valores de torque para criar modelo de corre\u00e7\u00e3o an\u00e1logo ao que corrige os valores de for\u00e7a Testes TCW - Valores de for\u00e7a e torque em 57 posi\u00e7\u00f5es com gripper e payload 0Kg Testes TCWNG - Valores de for\u00e7a e torque em 8 posi\u00e7\u00f5es sem gripper e payload 0Kg M\u00e1quina de Estados Global UR10e Inputs Double Tap X / Y / Z Finger Position Funcionalidades Working - Task predefinida pelo utilizador Reactive Stop - Em movimento manuais / pre definidos se sentir uma for\u00e7a p\u00e1ra e espera por input Freedrive - Robot move-se na dire\u00e7\u00e3o da for\u00e7a sentida Para a existencia de um movimento mais preciso, talvez alterar a rela\u00e7\u00e3o for\u00e7a-velocidade em real time Fine Control - Velocidade de opera\u00e7\u00e3o muito reduzida Ou criar um modelo que compreenda v\u00e1rias rela\u00e7\u00f5es de for\u00e7a-velocidade mas que a transi\u00e7\u00e3o entre elas seja \"seemless\" Deliver Object - Robot entrega ao utlizador um objeto fazendo-o lagar quando o utilizar exerce for\u00e7a suficnete para suster o objeto Implementar esta funcionalidade futuramente no controlo do robot atrav\u00e9s de gestos (m\u00e3os) Lift and Control - Levar o gripper at\u00e9 um objeto, dar input para ele o agarrar, fazer com que o bra\u00e7o levante o objeto, compense o seu peso e continue em modo freedrive Custom Screw - Colocar o robot numa posi\u00e7\u00e3o e faze-lo apertar algo (rodando o wrist_3) at\u00e9 notar que est\u00e1 a exercer for\u00e7a suficiente Modo de Configura\u00e7\u00e3o - ? Controlo das Luzes do Gripper Defini\u00e7\u00e3o de fun\u00e7oes de controlo dos LEDS do gripper no iris_sami Possivel contorlar anima\u00e7\u00e3o, cor, velocidade e mudan\u00e7a de modos pr\u00e9-definidos 08/06 - IRISLab Modelo de Corre\u00e7\u00e3o de Torque Testes nas 57 posi\u00e7\u00f5es com gripper e grava\u00e7\u00e3o dos valores de torque Teses em 8 posi\u00e7\u00f5es sem gripper para efetuar a corre\u00e7\u00e3o dos valores do sensor consoante a posi\u00e7\u00e3o do wrist_3 Cria\u00e7\u00e3o do programa positional_correction.py que utiliza os 8 testes anteriores e cria 2 arrays (for\u00e7a e torque) para serem utilizados pelos n\u00f3s de correc\u00e7\u00e3o 15/06 - IRISLab Modelo Te\u00f3rico de Corre\u00e7\u00e3o de Torque Adcionar ao ficheiro ft_sensor.py a parte te\u00f3rica do torque baseado da seguinte f\u00f3rmula Testes nas 57 posi\u00e7\u00f5es ao simulador no modelo te\u00f3rico e grava\u00e7\u00e3o dos valores de torque Compara\u00e7\u00e3o dos testes reais com os te\u00f3ricos mostram que o modelo te\u00f3rico de torque est\u00e1 bem desenhado mas os parametros precisam de ser ajustados Necessidade de criar um modelo que crie os testes ao modelo te\u00f3rico analiticamente (sem simula\u00e7\u00e3o e grava\u00e7\u00e3o) 21/06 - IRISLab Modelo de Corre\u00e7\u00e3o de Torque Valores do modelo te\u00f3rico utilizados na parte de corre\u00e7\u00e3o dos valores reais Ap\u00f3s alguns testes, o modo compliance do robot funciona muito melhor Necessidade de atualizar o valor do centro de gravidade do modelo quando o robot pega em algo Implementa\u00e7\u00e3o de constantes de convers\u00e3o FT -> Velocidade atrav\u00e9s de parametros do servidro dynamic reconfigure Constante de divis\u00e3o de For\u00e7a e Torque Sensibilidade 22/06 - IRISLab Modelo Te\u00f3rico Atualiza\u00e7\u00e3o do centro de gravidade do objeto e calculo do torque te\u00f3rico baseado nesse valor (PODE N\u00c3O ESTAR FEITO DO MELHOR FORMA) Calculo feito atrav\u00e9s da soma do peso do gripper * cog do gripper e peso do objeto * cog do objeto (fingers) Peso do objeto \u00e9 retirado diretamente dos valores de for\u00e7a medidos pelo sensor Devido \u00e0 imprecis\u00e3o da compoente for\u00e7a do sensor, o peso calculado nem sempre corresponde ao peso real Neste momento, o peso calculado parece sempre que \u00e9 superior ao peso real em 1.2x Existe o problema de quanto maior o peso do objeto mais imprecisoes existem nos valores medidos e quanto aos movimentos, o robot ir\u00e1 ter mais dificuladade em executalos visto que at\u00e9 agora, o payload configurado na interface do robot \u00e9 de 0Kg em vez do peso real Resets Peri\u00f3dicos Programa time_series_analysis.py que analisa uma amostra de 100 valores provenientes de wrench_filtered e analisa atrav\u00e9s do desvio padr\u00e3o dos dados se existem for\u00e7as externas a interagir com o robot 25/06 - Bilbioteca Limpar reposit\u00f3rio e ter apenas um workspace ROS com o driver atualizado Cria\u00e7\u00e3o de uma interface rqt para iris sami Cria\u00e7\u00e3o de um site mkdocs para escrever documenta\u00e7\u00e3o dos programas 29/06 - Biblioteca rqt iris sami ready for use 30/06 - Biblioteca Pull request iris-ua/iris_sami Pesquisa de estrutura para a tese 1/07 - IRISLab Interaction Componentes X, Y, Z do modulo double tap isoladas para permitir identificar v\u00e1rios tipos de toques no EE Em X, Y, Z e no sentido positivo e negativo permitindo 6 tipos diferentes de taps UR10e State Machine Implementa\u00e7\u00e3o de uma maquina de estados semelhante \u00e0 anterior mas utilizancho a bilbioteca ros smach Cada estado \u00e9 uma classe isolada com uma fun\u00e7\u00e3o execute Integra\u00e7\u00e3o muito poderosa com ROS Possibilidade de visualizar o estado corrente da m\u00e1quina atrav\u00e9s de smach_viewer Fix no interface do gripper onde a chamada repetida das fun\u00e7\u00f5es get_state e get_pos gerava exce\u00e7\u00f5es HTTP Necessidade de dar fix \u00e0 maneira como interagir com o gripper 7/07 - IRISLab Altera\u00e7\u00e3o do servi\u00e7o /iris_sami/status para 2 t\u00f3picos /iris_sami/arm_status (500Hz) e /iris_sami/gripper_status (50Hz) Cria\u00e7\u00e3o de 2 inst\u00e2ncias de controlo do gripper dentro do server.py do iris_sami Cria\u00e7\u00e3o do n\u00f3 weight que calcula constantemente a magnitude da for\u00e7a exercida no sensor FT 8/07 - IRISLab Modelo Te\u00f3rico de Corre\u00e7\u00e3o de Torque C\u00e1lculo da segunda parte da equa\u00e7\u00e3o utilizando para cada eixo um plano perpendicular ao eixo, onde se ira projetar o vetor garvidade Ao inves de criar o plano utilizando o vetor gravidade e projetar o eixo Calculo do COG utilizando as medidas de for\u00e7a e torque Quando o gripper esta acopulado, as medidas de for\u00e7a e torque s\u00e3o 0 (ele est\u00e1 compensado) Inicialmente calcular o COG do gripper com medidas de for\u00e7a e torque -> guardar valores Depois, dinamicamnete, quando se pega num objeto, calcular peso e cog com medidas de for\u00e7a e torque -> atualizar o modelo Divis\u00e3o dos parametros de sensibilidade em for\u00e7a e torque 12/07 - Biblioteca Modelo Te\u00f3rico de Corre\u00e7\u00e3o de Torque Gera\u00e7\u00e3o de poses correspondentes ao conjunto de 58 combina\u00e7\u00f5es de juntas para teste do modelo te\u00f3rico Lista de poses guradada em curves/poses_58.list Altera\u00e7\u00e3o do modelo te\u00f3rico para ser extens\u00edvel ao calculo de for\u00e7a e torque Cria\u00e7\u00e3o da fun\u00e7\u00e3o theoryFT que dada uma pose, calcula a for\u00e7a e o torque te\u00f3rica que um objeto com um dado peso e COG teria Altra\u00e7\u00e3o do programa plot.py que compara os testes reais com os te\u00f3ricos onde a cada compara\u00e7\u00e3o, um novo teste te\u00f3rico \u00e9 corrido, visto que temos conhecimentos das poses que foram utilizadas Altera\u00e7\u00e3o da equa\u00e7\u00e3o de gera\u00e7\u00e3o de torques no programa ft_theory.py Valores gerados teoricamente est\u00e3o muito mais pr\u00f3ximos dos valores reais e prontos para ser utilizados 14/07 - Biblioteca Scan do Ambiente Externo ao Robot Adi\u00e7\u00e3o dos xacros de uma orbec astra ao EE do robot Programa environment.cpp que guarda uma point cloud global correspondente ao ambiente Expoe um servi\u00e7o que quando chamado, recolhe um asample RGBD, recolhe o TF da camera e adiciona a sample ao ambiente de forma incremental Programa scan.py coordena os movimentos do robot e a chamada ao servi\u00e7o de take_sample 16/07 - IRISLab Modelo de Compensa\u00e7\u00e3o de Torque Implementa\u00e7\u00e3o da atividade de pegar num objeto com a maquina de estado escrita em ros_smach Calculo do peso do objeto ainda precisa de ser melhorado Cria\u00e7\u00e3o de testes para calcular o COG do gripper e posteriormente do objeto 21/07 - Reuni\u00e3o Finaliza\u00e7\u00e3o do tema de compensa\u00e7\u00e3o de for\u00e7a e torque Discuss\u00e3o do modo de transi\u00e7\u00e3o de estados da m\u00e1quina de estados do robot Discuss\u00e3o da melhor forma de abordar o tema de calculo de trajet\u00f3rias com obstaculos Discuss\u00e3o da estrutura do \u00edndice da tese 23/07 - Bilbioteca Setup do ambiente Latex para a escrita do documento Primeira vers\u00e3o provis\u00f3ria do \u00ednidice da tese","title":"Logbook"},{"location":"logbook/#logbook","text":"","title":"Logbook"},{"location":"logbook/#1011-pesquisar-papers-bronze","text":"Encontrei +30 papers sobre intera\u00e7\u00e3o de robots industriais e humanos. Guardei para futura leitura e resumo Sites de papers cient\u00edficos ResearchGate IEEEXplore Science Direct Encontrei 3 sites com recursos interessantes para o tema RIA - https://www.robotics.org/ UR - https://www.universal-robots.com/ A3 - https://www.a3automate.org/","title":"10/11 - Pesquisar papers (Bronze)"},{"location":"logbook/#1111-reuniao-irislab","text":"Com o Prof Nuno Lau e Bernardo Cunha Apresenta\u00e7\u00e3o do Projeto Augmanity, composi\u00e7\u00e3o do sistema, datas e entreg\u00e1veis Escrita da tese fica para o final do desenvolvimento In\u00edcio do logbook","title":"11/11 - Reuni\u00e3o (IRISlab)"},{"location":"logbook/#tarefas","text":"Passagem de objeto do robot para humano Utiliza\u00e7\u00e3o de posi\u00e7oes pr\u00e9 definidas Leitura do sensor de 3 eixos do end-efector para o robot largar o objeto","title":"Tarefas"},{"location":"logbook/#1611-pesquisa-posto","text":"Ao pesquisar sobre o sensor de for\u00e7a do end-efector (TCP), descobri que o driver oficial publica no t\u00f3pico /wrench os valores que l\u00ea do sensor","title":"16/11 - Pesquisa (Posto)"},{"location":"logbook/#1711-teste-irislab","text":"Ao iniciar um novo workspace com o reposit\u00f3rio do driver oficial, o driver inicia sem problema, e publica no t\u00f3pico /wrench 3 valores de for\u00e7a e 3 valores de torque. Existe no entanto o problema de n\u00e3o consegui conectar o MoveIt ao robot, com erros variados Um deles estava relacionado com a aus\u00eancia de um ficheiro de calibra\u00e7\u00e3o interna, que ap\u00f3s o obter, resolvi o problema Ao tentar dar merge do novo driver com o reposit\u00f3rio do Eurico, os erros persistiram Ao tentar dar merge novamente em casa, consegui compilar o projeto e executar sem problemas no gazebo. Penso que \u00e9 esperado visto que os problemas est\u00e3o maioritariamente no driver do robot real","title":"17/11 - Teste (IRISLab)"},{"location":"logbook/#repositorios-importantes","text":"Eurico - https://github.com/iris-ua/iris_ur10e UR Driver - https://github.com/UniversalRobots/Universal_Robots_ROS_Driver UR Description e MoveIt (recomendado) - https://github.com/fmauch/universal_robot/tree/calibration_devel Este possui um branch interessante \"moveit\" cuja pasta ur10e_moveit_config \u00e9 mais recente que todas as outras UR Description e MoveIt (oficial) - https://github.com/ros-industrial/universal_robot Criei 3 workspaces diferentes. 1 com o driver do eurico (iris_ws). 1 com o driver oficial (ros_ws). 1 onde vou tentar dar merge dos 2 (merge_ws)","title":"Reposit\u00f3rios Importantes"},{"location":"logbook/#1811-reuniao-irislab","text":"Ao tentar adaptar o merge_ws para os parametros do iris_ws (que funciona) reparei numa linha do ur10e_bringup.launch onde, por alguma razao, o force_torque_sensor_controller nao estava incluido na lista de controladores. Ao incluir, o driver j\u00e1 publica os valores do sensor para o t\u00f3pico /wrench. Vou prosseguir com a utiliza\u00e7\u00e3o do iris_ws, deixando a adapta\u00e7\u00e3o do merge_ws para depois. Implementa\u00e7\u00e3o do planeador STOMP no iris_ws Adapta\u00e7\u00e3o do n\u00f3 ArmControl ao ambiente (remo\u00e7\u00e3o de c\u00f3digo relativo ao iris_cork) Valores de torque do t\u00f3pico /wrench s\u00e3o cartesianos e e relativos ao tool0_controller mas os valores iniciais n\u00e3o s\u00e3o claros. O y inicia com um valor demasiado alto e a rota\u00e7\u00e3o do end-effector n\u00e3o parece impactuar esses valores. Afinal, apos reinicar o robot e ler logo a seguir os valores de /wrench, ficam todos muito pr\u00f3ximos de 0 Ap\u00f3s algum tempo a testar, \u00e9 n\u00edtido que a cada reboot do robot, os valores iniciais de for\u00e7a s\u00e3o inicializados a zero. Como era de esperar, diferentes posi\u00e7oes do gripper provocam altera\u00e7\u00e3o nos valores de for\u00e7a (os valores podem alterar-se at\u00e9 +/- 10) permanecendo nesse estado. Os valores n\u00e3o parecem ser absolutos, mas sim relativos \u00e0 posi\u00e7\u00e3o inicial em que o robot \u00e9 ligado V\u00e1rias reinicializa\u00e7\u00f5es do driver n\u00e3o provocam altera\u00e7\u00e3o nos valores de for\u00e7a Muito possivelmente, a melhor forma de utilizar os valores deste sensor, ser\u00e1 apenas utilizando a diferen\u00e7a de for\u00e7a com o tempo, pois se o gripper se mantiver est\u00e1vel, os valores variam em +/- 1 sendo que a aplica\u00e7\u00e3o de uma for\u00e7a adequada por parte do utilizador ao gripper, provoca varia\u00e7\u00e3o nos valores em +/- 15 (Newtons?) Valores de torque ainda s\u00e3o uma inc\u00f3gnita -> J\u00e1 n\u00e3o s\u00e3o uma inc\u00f3gnita. Valores de torque representam for\u00e7as circulares aplicadas ao end efector Alterar a orienta\u00e7\u00e3o do gripper faz com que os valores de for\u00e7a se alterem... Mesmo o robot estando est\u00e1tico","title":"18/11 - Reuni\u00e3o (IRISLab)"},{"location":"logbook/#tarefas_1","text":"Recolher valores do sensor tendo em conta a varia\u00e7\u00e3o de Poses de inicializa\u00e7\u00e3o do robot V\u00e1rias poses do robot V\u00e1rias orienta\u00e7\u00f5es do gripper Com e sem um um objeto 4 bags gravados (wrench3, wrench10, all3, all10) Testes com novo n\u00f3 tests.py para criar diferentes conjuntos de posi\u00e7\u00f5es","title":"Tarefas"},{"location":"logbook/#1911-irislab","text":"\u00c0 medida que o tempo passa, o sensor de for\u00e7a vai acumulando erros e, sem mexer no robot, os valores v\u00e3o-se afastando linearmente de como s\u00e3o inicializados (0,0,0) Programa de testes em que o EE se mexe em XYZ sem alterar orienta\u00e7\u00e3o provoca for\u00e7as irrelevantes no sensor Recalibra\u00e7\u00e3o do TCP Valores actuais - {Payload: 1.77kg, CX: -5.0, CY: 0.0, CZ: 45.0} Calibra\u00e7\u00e3o 1 - {Payload: 1.67kg, CX: -3.0, CY: 0.0, CZ: 41.0} Calibra\u00e7\u00e3o 2 - {Payload: 1.84kg, CX: -1.0, CY: 1.0, CZ: 37.0} Calibra\u00e7\u00e3o 3 - {Payload: 1.84kg, CX: -5.0, CY: -5.0, CZ: 38.0} Calibra\u00e7\u00e3o 4 - {Payload: 1.73kg, CX: -3.0, CY: 2.0, CZ: 49.0} Calibra\u00e7\u00e3o 5 - {Payload: 1.69kg, CX: 10.0, CY: 0.0, CZ: 39.0 Agora com o Gripper Fechado Calibra\u00e7\u00e3o 6 - {Payload: 1.76kg, CX: -1.0, CY: -3.0, CZ: 40.0} Calibra\u00e7\u00e3o 7 - {Payload: 1.67kg, CX: -1.0, CY: 3.0, CZ: 48.0} Calibra\u00e7\u00e3o 8 - {Payload: 1.63kg, CX: 1.0, CY: -5.0, CZ: 47.0} Agora Reinicializando o Robot Calibra\u00e7\u00e3o 9 - {Payload: 1.72kg, CX: -2.0, CY: -8.0, CZ: 40.0} Calibra\u00e7\u00e3o 10 - {Payload: 1.69kg, CX: -8.0, CY: -2.0, CZ: 40.0} Ap\u00f3s v\u00e1rias tentativas de calibra\u00e7\u00e3o, decidi usar os valores atuais mas centrar o TCP em X = 0","title":"19/11 - IRISLab"},{"location":"logbook/#212-irislab","text":"Estudo dos valores de for\u00e7a do sensor, gr\u00e1ficos em screenshots -> wrench Pasta 1-wrench Movimentos simples em XYZ sem aplicar rota\u00e7\u00e3o do EE, provocam oscila\u00e7\u00f5es quando o robot se est\u00e1 a mover. Valores oscilam entre [-5, 6] Rota\u00e7\u00f5es do EE provocam maiores oscila\u00e7\u00f5es e estes valores permanecem alterados, ap\u00f3s a rota\u00e7\u00e3o. Ver screenshots TESTE - Mover 3 vezes, pi/4 graus - Mover -3*pi/4 graus - Mover 3 vezes, -pi/4 graus - Mover 3*pi/4 graus NOTA - Rota\u00e7\u00f5es positivas, EE roda no sentido hor\u00e1rio RESULTADO - A posi\u00e7\u00e3o do EE influencia a amplitude dos valores e nota-se um padr\u00e3o constante nas 3 posi\u00e7\u00f5es experimentadas Altera\u00e7\u00e3o do peso do payload TESTE - Alterar o peso do payload para 1.4kg RESULTADO - A amplitude dos valores diminuiu em X mas aumentou em Y TESTE - Alterar o peso do payload para 1kg RESULTADO - Houve uma alter\u00e7\u00e3o nos valores de X (como que uma invers\u00e3o), e a amplitude de valores em Y aumentou significativamente TESTE - Alterar o peso do payload para 2kg RESULTADO - Mais uma vez, os valores em X inverteram-se, e a amplitude de valores em Y diminuiu NOTA - O problema n\u00e3o parece estar apenas relacionado com peso mas tamb\u00e9m com o centro de gravidade Recalibrar o peso e centro de gravidade do TCP Novos valores - {Payload: 1.71kg, CX: -1.0, CY: 0.0, CZ: 41.0} RESULTADO - Exatamente o mesmo do primeiro teste de rota\u00e7\u00e3o Novos valores - {Payload: 1.79kg, CX: 3.0, CY: 2.0, CZ: 36.0} RESULTADO - Exatamente o mesmo do primeiro teste de rota\u00e7\u00e3o Testar os movimentos simples em XYZ ap\u00f3s uma rota\u00e7\u00e3o revela o esperado, ou seja, inicialmente, os valores alteram-se drasticamente na rota\u00e7\u00e3o, no entanto, durante as transla\u00e7\u00f5es, as oscila\u00e7\u00f5es s\u00e3o muito menores Altera\u00e7\u00e3o do Centro de Gravidade TESTE - Alterar para X = 0, Y = 0, Z = 0 RESULTADO - Exatamente o mesmo do primeiro teste de rota\u00e7\u00e3o TESTE - Alterar para X = 50, Y = 50, Z = 50 RESULTADO - Exatamente o mesmo do primeiro teste de rota\u00e7\u00e3o Alterar o valor do peso do payload ou qualquer componente do centro de gravidade do TCP faz com que o controlador do sensor reinicie os seus valores a zero, por menor que seja a altera\u00e7\u00e3o, qualquer que seja, provoca um reset Reposit\u00f3rio iniciado com o iris_ws -> https://github.com/fabioalves98/HumanRobotColaboration Programa wrench.py faz agora display dos valores num gr\u00e1fico em tempo real no modo live","title":"2/12 - IRISLab"},{"location":"logbook/#312-irislab","text":"Ver os resultados em tempo real n\u00e3o ajudou a obter novas conclus\u00f5es Os valores de for\u00e7a que o controlador interno do robot publica, s\u00e3o relativos ao eixo da base robot. O n\u00f3 ur_hardware_interface, antes de publicar para /wrench, multiplica estes valores pelo transform da pose do TCP para obter os valores de for\u00e7a em rela\u00e7\u00e3o ao TCP","title":"3/12 - IRISLab"},{"location":"logbook/#412-irislab","text":"Guardados 3 novos bags wrench_pushes.bag - Onde o gripper agarra num peda\u00e7o de corti\u00e7a e eu puxo em v\u00e1rias dire\u00e7\u00f5es com diferentes n\u00edveis de for\u00e7a wrench_taps.bag - Leves toques r\u00e1pidos nos lados do gripper wrench_twists.bag - Onde ao agarra no gripper o tento rodar em v\u00e1rias dire\u00e7\u00f5es para testar a sensibilidade dos valores de torque","title":"4/12 - IRISLab"},{"location":"logbook/#712-posto","text":"Descobri um servi\u00e7o que reinicializa o sensor de for\u00e7a e torque (zero_ftsensor) e outro que reenvia um programa URScript ao robot (resend_robot_program), \u00fatil para quando o robot entra em protective stop ou emergency stop Encontrei Issues no Github do driver do UR10e muito parecidos com o problema Programa wrench integra os valores de /wrench em tempo real para detetar corretamente uma intera\u00e7\u00e3o com o robot","title":"7/12 - Posto"},{"location":"logbook/#tarefas_2","text":"Filtar os valores de ru\u00eddo e fazer uma fun\u00e7\u00e3o de integra\u00e7\u00e3o que detete corretamente for\u00e7as e toques r\u00e1pidos Moving Average Filter - https://maker.pro/arduino/tutorial/how-to-clean-up-noisy-sensor-data-with-a-moving-average-filter Kalman Filter - ?","title":"Tarefas"},{"location":"logbook/#912-reuniao-irislab","text":"Programa wrench avalia os valores de for\u00e7a e consoante a for\u00e7a aplicada em cada eixo, abre ou fecha o gripper. Valor de for\u00e7a \u00e9 parametrizavel. No eixo X (lateral), uma for\u00e7a em qualquer dor sentidos fecha o gripper No eixo Y e Z (frontal, uma for\u00e7a no sentido do utilizador abre o gripper Continua o mesmo problema em que se o EE rodar, os valores alteram-se O driver obtem os valores de FT atraves de um cliente RTDE que comunica com um servidor presente no controlador interno do UR10e. Esse servidor publica os valores de for\u00e7a que calcula em rela\u00e7\u00e3o ao eixo do robot, e depois o driver transforma-os para a pose do TCP Para solucionar, \u00e9 poss\u00edvel usar a nova fun\u00e7\u00e3o que integra os valores e aplica um filtro de m\u00e9dia para controlar o gripper. Desta forma o controlo do gripper nao \u00e9 afetado pelas sucessivas rota\u00e7\u00f5es e movimentos do robot e acumula\u00e7\u00f5es de erro do sensor FT","title":"9/12 - Reuni\u00e3o (IRISLab)"},{"location":"logbook/#1712-teste-irislab","text":"Nova tentativa de resolver o problema do wrench. Retirar os valores de for\u00e7a em todos os angulos possiveis, por num gr\u00e1fico, tentar descobrir um padr\u00e3o a fim de compensar o comportantomento an\u00f3malo do controlador Pasta 2-wrench Posi\u00e7oes P1 - out_of_camera P2 - P1 -> rotate 0 -pi/4 0 P3 - P1 -> rotate 0 -pi/2 P4 - P1 -> rotate 0 -3/4 0 P5 - P1 -> rotate 0 pi/4 0 P6 - P1 -> rotate 0 0 pi/4 P7 - P1 -> rotate 0 0 -pi/4 Testes Teste 1 | Posi\u00e7\u00e3o 1 | zero_ftsensor quando wrist3_joint est\u00e1 a 0 |-180 a 180 Teste 2 | Posi\u00e7\u00e3o 1 | zero_ftsensor quando wrist3_joint est\u00e1 a -180 | -180 a 180 Teste 3 | Posi\u00e7\u00e3o 1 | zero_ftsensor quando wrist3_joint est\u00e1 a 180 | -180 a 180 Fixar os eixos do gr\u00e1fico para todos os testes ficarem com os mesmos eixos Teste 4 | Posi\u00e7\u00e3o 1 | zero_ftsensor quando wrist3_joint est\u00e1 a 0 | -180 a 180 Teste 5 | Posi\u00e7\u00e3o 2 | zero_ftsensor quando wrist3_joint est\u00e1 a 0 | -180 a 180 Teste 6 | Posi\u00e7\u00e3o 3 | zero_ftsensor quando wrist3_joint est\u00e1 a 0 | -180 a 180 Teste 7 | Posi\u00e7\u00e3o 4 | zero_ftsensor quando wrist3_joint est\u00e1 a 0 | -180 a 180 Teste 8 | Posi\u00e7\u00e3o 5 | zero_ftsensor quando wrist3_joint est\u00e1 a 0 | -180 a 180 Teste 9 | Posi\u00e7\u00e3o 6 | zero_ftsensor quando wrist3_joint est\u00e1 a 0 | -180 a 180 Teste 10 | Posi\u00e7\u00e3o 7 | zero_ftsensor quando wrist3_joint est\u00e1 a 0 | -180 a 180 Inconclusivos","title":"17/12 - Teste (IRISLab)"},{"location":"logbook/#1812-teste-irislab","text":"Nova tentativa de resolver o problema do wrench. Fazer os mesmos testes anteriores mas sem o gripper attached ao robot Pasta 3-wrench Posi\u00e7\u00f5es P1 - Joints [0, -90, 0, 0, 0, 0] P2 - Joints [0, -90, 0, 0, 90, 0] P3 - Joints [0, -90, 0, 0, -90, 0] P4 - Joints [0, -90, 0, 0, -45, 0] P5 - Joints [0, -90, 0, 0, 45, 0] P6 - out_of_camera P7 - init_calibration P8 - desk_pick Novo gr\u00e1fico com valores de torque","title":"18/12 - Teste (IRISLab)"},{"location":"logbook/#0801-desenvolvimento-bmilhavo","text":"Programa fit.py que dessenha 3 fun\u00e7\u00f5es seno, configuradas de maneira diferente de modo a tentar aproximar as curvas obtidas nos programas de teste do wrench.py Curvas aparentam ter proximidade com os gr\u00e1ficos do wrench.py","title":"08/01 - Desenvolvimento (BMIlhavo)"},{"location":"logbook/#1301-reuniao-irislab","text":"Novos testes com persistencia dos resultados em mem\u00f3ria, sem gripper Pasta F-wrench Posi\u00e7\u00f5es P1 - Joints [0, -90, 0, 0, 90, 0] P2 - Joints [0, -90, 0, 0, 45, 0] P3 - Joints [0, -90, 0, 0, 0, 0] P4 - Joints [0, -90, 0, 0, -45, 0] P5 - Joints [0, -90, 0, 0, -90, 0 M\u00e9dia e desvio padr\u00e3o das diferen\u00e7as dos resultados Mean - [ 0.41535386, 0.4073297 , 0.48555393] Std Dev - [ 0.07199976, 0.07887803, 0.09579287]","title":"13/01 - Reuni\u00e3o (IRISLab)"},{"location":"logbook/#to-do","text":"Verificar repetibilidade dos testes Verificar se dar resest em angulos de wrist_3 diferentes provoca os mesmos resultados Verificar o drift do sensor, tanto temporal como espacial Verificar os valores de TCP Force pelo URScript Dar fit de uma fun\u00e7\u00e3o seno nos resultados M\u00e9todo dos m\u00ednimos quadrados Criar modelo que aplique a fun\u00e7\u00e3o para corrigir a vari\u00e2ncia dos valores de for\u00e7a","title":"To Do"},{"location":"logbook/#0103-irislab","text":"","title":"01/03 - IRISLab"},{"location":"logbook/#repetibilidade","text":"Repeti\u00e7\u00e3o dos testes para verificar repetibilidade dos resultados Pasta F-wrench (repeat) Posi\u00e7\u00f5es e diferen\u00e7a de valores comparado com os testes anteriores P1 - Joints [0, -90, 0, 0, 90, 0] Mean - [ 0.20678017, 0.49250442, 0.29758366] Std Dev - [ 0.16025934, 0.125027 , 0.21015851] P2 - Joints [0, -90, 0, 0, 45, 0] Mean - [ 0.29473815, 0.69158735, 0.89929321] Std Dev - [ 0.17148463, 0.43221503, 0.27771454] P3 - Joints [0, -90, 0, 0, 0, 0] Mean - [ 0.30978849, 0.37630247, 0.34874062] Std Dev - [ 0.18629143, 0.18554891, 0.18170008] P4 - Joints [0, -90, 0, 0, -45, 0] Mean - [ 0.13864991, 0.2199402 , 0.5447835] Std Dev - [ 0.09905205, 0.16799613, 0.25183081] P5 - Joints [0, -90, 0, 0, -90, 0] Mean - [ 0.35275194, 0.41744611, 0.24365676] Std Dev - [ 0.21623916, 0.33241225, 0.18720336] M\u00e9dia e desvio padr\u00e3o das diferen\u00e7as dos resultados Mean - [ 0.48826575, 0.48218191, 0.70701964] Std Dev - [ 0.11487946, 0.14974243, 0.16440651] Resultado - Todos os testes aparentam ser pass\u00edveis de ser repetidos e apresentar os mesmos valores M\u00e9dia e desvio padr\u00e3o do conjunto dos 10 testes Mean - [ 0.43229188, 0.47148803, 0.56602416] Std Dev - [ 0.07462753, 0.15599019, 0.10256855]","title":"Repetibilidade"},{"location":"logbook/#dar-reset-noutro-sitio-e-sobrepor-os-valores","text":"Teste T6 - Posi\u00e7\u00e3o P5 - /zero_ft_sensor chamado com wrist_3 = -75 Resulta em curvas com o mesmo padr\u00e3o mas deslocadas verticalmente Utilizando o fit.py para dar plot de T5 e T6 Resultado - Se compensarmos T6 com o valor de T5 em wrist_3 = 75, obtemos T5 com pouca variabilidade de (< 0.5N)","title":"Dar reset noutro s\u00edtio e sobrepor os valores"},{"location":"logbook/#drift-temporal","text":"Teste TD - Posi\u00e7\u00e3o P2/P3/P4 - /zero_ft_sensor chamado com wrist_3 = 0 Gravar valores durante 10 minutos sem movimento Resultado - Os valores variam linearmente com o tempo","title":"Drift Temporal"},{"location":"logbook/#0203-irislab","text":"Peso do Gripper - 1.336 Kg Peso do Encaixe do Gripper - 0.178 g Peso do Conjunto - 1.514 Kg","title":"02/03 - IRISLab"},{"location":"logbook/#drift-posicional","text":"Teste TP - Posi\u00e7\u00e3o P1 - /zero_ft_sensor chamado com wrist_3 = 0 Mover o bra\u00e7o para uma posi\u00e7\u00e3o random - \"out_of_camera\" Aplicar 180 graus de rota\u00e7\u00e3o no wrist_3 Voltar para a posi\u00e7\u00e3o P1 Correr o teste sem dar reset no inicio do teste Resultado - Comparando com o teste default T1_P1 n\u00e3o h\u00e1 vari\u00e2ncia not\u00e1vel nos resultados Correr o teste mas dar reset no in\u00edcio do teste Resultado - Comparando com o teste default T1_P1 n\u00e3o h\u00e1 vari\u00e2ncia not\u00e1vel nos resultados","title":"Drift Posicional"},{"location":"logbook/#fit-de-uma-funcao-seno","text":"Aplica\u00e7\u00e3o da fun\u00e7\u00e3o curve_fit da bilbioteca scipy, com uma fun\u00e7\u00e3o custumizada seno com 4 parametros y = p1 * np.sin(np.radians(p2 * (x + p3))) + p4 Amplitude, frequencia, offset_x, offset_y Defini\u00e7\u00e3o de valores de guess iniciais Resultado - Parametros finais x - [3.59403687, 2.16328845, -56.15475734, 2.55574389] y - [1.18181371, 2.16484226, 39.16549121, -0.45171281] z - [1.96991165, 2.00442201, 41.65549264, -2.1853712 ]","title":"Fit de uma Fun\u00e7\u00e3o Seno"},{"location":"logbook/#0303-irislab-reuniao","text":"Tentativa de corrigir os valores de for\u00e7a vindo do wrench em tempo real Problemas no geral. Poss\u00edveis causas Maneira de obter o valor do wrist_3 do robot Problema de velocidade dos t\u00f3picos Problema em acesso com exclusividade mutua aos valores no wrench.py Reuni\u00e3o - To Do Dar merge das curvas com gripper e sem gripper Fazer modelo te\u00f3rico de como o gripper se dever\u00e1 comportar em diferentes orienta\u00e7\u00f5es Parametros seriam a orienta\u00e7\u00e3o do gripper, peso e centro de gravidade Usar esse modelo te\u00f3rico, repetir os testes e melhorar o modelo com testes V\u00eddeos - https://www.youtube.com/c/EnergidTechnologies/videos","title":"03/03 - IRISLab (Reuni\u00e3o)"},{"location":"logbook/#0503-irislab","text":"Repeti\u00e7\u00e3o dos teses com o Gripper attatched Pasta F-Wrench Mesmas 5 posi\u00e7\u00f5es que anteriormente Mais uma B\u00f3nus - out_of_camera","title":"05/03 - IRISLab"},{"location":"logbook/#testes-com-valores-diferentes-de-payload-e-cov","text":"Diferetes valores de payload alteram drasticamente os valores do sensor Diferentes valores de centro de gravidade n\u00e3o alteram os valores do sensor","title":"Testes com valores diferentes de Payload e COV"},{"location":"logbook/#merge-das-curvas-com-e-sem-gripper","text":"Valores de diferen\u00e7a entre curvas originais e com gripper fazem algum sentido, mas n\u00e3o s\u00e3o suficientes para retirar Valores de diferen\u00e7a em X, fazem sentido pois a posi\u00e7\u00e3o wrist_3 = 0 tem o eixo X alinhado verticalmente, ou seja, quando ha o zerto_ft_sensor(), todo o peso do gripper est\u00e1 sobre esse eixo, e h\u00e1 medida que rodamos, esse peso vai passando para o eixo Y, logo \u00e9 normal que o valor de X aumente A parte estranha \u00e9 que o valor de Y n\u00e3o se altera em todo o teste Ainda mais estranho, \u00e9 que o valor de Z se altera Uma poss\u00edvel explica\u00e7\u00e3o \u00e9 que estes 2 testes diferem no valor configurado de payload Quando foram medidos sem gripper - Payload era 0Kg Quando foram medidos com gripper - Payload era 1.77Kg Resultado - Inconclusivo","title":"Merge das Curvas com e sem Gripper"},{"location":"logbook/#0603-casa","text":"Refactor do workspace com os pacotes iris_sami e iris_ur10e Refactor de c\u00f3digo com helper functions","title":"06/03 - Casa"},{"location":"logbook/#0703-casa","text":"Paper - Human\u2013robot interaction in industrial collaborative robotics: a literature review of the decade","title":"07/03 - Casa"},{"location":"logbook/#0803-irislab","text":"","title":"08/03 - IRISLab"},{"location":"logbook/#testes-com-diferentes-valores-de-payload-sem-gripper","text":"Pasta F-Wrench Teste Payload | Posi\u00e7\u00e3o 1 | Payload de x Kg TP1_0Kg Igual ao teste default TP1_0.2Kg e TP1_1Kg Exatamente igual a TP1_0Kg TP2_0Kg Igual ao teste default TP2_0.2kg e TP2_1Kg Apresentam diferen\u00e7as significativas em rela\u00e7\u00e3o a TP2 que fazem todo o sentido Repeti\u00e7\u00e3o para a P3 com resultados analogos a P1, ou seja, as diferen\u00e7as foram ainda maiores Resutlado - Ap\u00f3s verifica\u00e7\u00e3o dos resultados corrigidos faz todo o sentido Ao adicionarmos valores falsos de payload, eles v\u00e3o ser retratados nas curvas","title":"Testes com diferentes valores de payload sem Gripper"},{"location":"logbook/#teste-com-payload-0-com-e-sem-gripper-sem-dar-reset-entre-os-testes","text":"Posi\u00e7\u00e3o B - [0, -90, -90, 0, 0, 0] Teste Payload | Posi\u00e7\u00e3o B | Payload de x Kg TPB_0Kg Igual ao teste default TPBG_0Kg Diferen\u00e7as extremas devido ao acopulamento do gripper, os valores fazen sentido, no geral For\u00e7a com que o gripper \u00e9 acopulado ao end effector interfere com os valores de Z Restulado - Compensas\u00e3o dos valores obtidos com a acopula\u00e7\u00e3o do gripper demonstram curvas sinosoidais realistas e cujos valores fazem sentido Obten\u00e7\u00e3o do peso do gripper fazendo primeiro Compensas\u00e3o da component Z com a sua m\u00e9dia A raiz dos quadrados das 3 compoentes Obtemos a cada posi\u00e7\u00e3o de wrist_3 a magnitude do vector forca Fazendo a m\u00e9dia obteve-se o valor de 15.13 N O peso do conjunto \u00e9 de 1.514 Kg","title":"Teste com Payload 0 com e sem gripper (sem dar reset entre os testes)"},{"location":"logbook/#testes-com-diferentes-valores-de-payload-com-gripper","text":"Obter o melhor valor de peso para inserir no payload Posi\u00e7\u00e3o B - [0, -90, -90, 0, 0, 0] Teste Payload | Posi\u00e7\u00e3o B | Payload de x Kg Testados payloads de 1.2kg a 1.8Kg com intervalos de 100g Objetivo \u00e9 ver qual payload \u00e9 que produz a curva mais aproximada \u00e0 curva de corre\u00e7\u00e3o Resultado - Nenhuma curva de aproxima completamente mas as mais pr\u00f3ximas em termos de m\u00e9dia e desvio padr\u00e3o s\u00e3o 1.5Kg e 1.6kg que \u00e9 aproximadamente o peso do gripper Os desvios poder\u00e3o estar a ser causados pelo COG","title":"Testes com diferentes valores de payload com Gripper"},{"location":"logbook/#0903-irislab","text":"","title":"09/03 - IRISLab"},{"location":"logbook/#testes-com-diferentes-valores-de-cog-com-gripper","text":"Testar impacto de COG nas curvas obtidas Teste COG | Posi\u00e7\u00e3o [1, 2, 3] Center of Gravity com 0mm em todas as componentes Center of Gravity com 100mm em todas as componentes Center of Gravity com 200mm em todas as componentes Resultado - Parece haver alguma varia\u00e7\u00e3o mas nem suficientemente grande que necessite de ser corrigida, nem apresenta um padr\u00e3o definido","title":"Testes com diferentes valores de COG com gripper"},{"location":"logbook/#testes-com-gripper-em-diferentes-posicoes-e-payloads","text":"Testar o efeito de diferentes valores em diferentes posi\u00e7\u00f5es Teste Payload | Posi\u00e7\u00e3o [1, 2, 3, 4, 5] | Payload [0, 1.5, 3] Resultado Tanto na posi\u00e7\u00e3o 1 como 5 as curvas n\u00e3o apresentaram diferen\u00e7as cosoante a altera\u00e7\u00e3o do payload, como era esperado Nas posi\u00e7\u00f5es 2, 3 e 4 as curvas apresntam diferen\u00e7as nas magnitudes esperadas No entanto, quando corrigidas em 1.5kg (peso real do gripper) apresentam algumas oscila\u00e7\u00f5es que ter\u00e3o que ser corrigidas","title":"Testes com Gripper em diferentes posi\u00e7\u00f5es e payloads"},{"location":"logbook/#1503-irislab","text":"","title":"15/03 - IRISLab"},{"location":"logbook/#obter-melhor-peso-do-gripper-com-varias-posicoes-e-payloads","text":"Voltar a tentar testar o melhor valor de payload introduzido no robot para ver se \u00e9 poss\u00edvel obter uma \u00fanica curva em v\u00e1rias posi\u00e7\u00f5es A curva do gripper n\u00e3o tem que ser necessariamente igual \u00e0 curva sem gripper, no entanto, n\u00e3o pode mudar consoante a posi\u00e7\u00e3o Teste Gripper | Posi\u00e7\u00e3o 1 [1, 2, 3, 4, 5] | Payloads [1.4, 1.5, 1.6] Resultado Os testes s\u00e3o repet\u00edveis - caso de exemplo 1.5kg Estas diferen\u00e7as no payload s\u00e3o representadas nos resultados, sendo que 1.5Kg \u00e9 o valor que mais se aproximo \u00e0 curva default (sem gripper)","title":"Obter melhor peso do Gripper com v\u00e1rias posi\u00e7\u00f5es e payloads"},{"location":"logbook/#1603-irislab","text":"","title":"16/03 - IRISLab"},{"location":"logbook/#conjunto-extenso-de-poses-de-forma-abrangir-o-maior-numero-de-orientacoes","text":"Array de angulos - [-180, -135, -90, -45, 0, 45, 90, 135, 180] 2 ciclos de itera\u00e7\u00e3o por este array e atribu\u00e7\u00e3o de valor de junta a wrist_1 e wrist_2 Total de 70 posi\u00e7\u00f5es","title":"Conjunto extenso de poses de forma abrangir o maior n\u00famero de orienta\u00e7\u00f5es"},{"location":"logbook/#modelo-teorico-do-comportamento-do-sensor-de-forca-quando-o-gripper-esta-acopulado","text":"3 vetores com a orienta\u00e7\u00e3o do Sensor 1 vetor com magnitude e orienta\u00e7\u00e3o da gravidade Calcular teoricamente cada componente do vetor gravidade em cada 1 dos 3 eixos do sensor FT","title":"Modelo te\u00f3rico do comportamento do sensor de for\u00e7a quando o gripper est\u00e1 acopulado"},{"location":"logbook/#1703-irislab","text":"","title":"17/03 - IRISLab"},{"location":"logbook/#conclusao-do-modelo-teorico-do-sensor","text":"Utiliza\u00e7\u00e3o do produto interno dos vetores normalizados anteriormente definidos para calculo do valor da for\u00e7a em cada componente","title":"Conclus\u00e3o do modelo te\u00f3rico do sensor"},{"location":"logbook/#1803-irislab","text":"","title":"18/03 - IRISLab"},{"location":"logbook/#teste-de-cog-no-robot-real","text":"Com uma tabua de um metro acopulada ao gripper numa posi\u00e7\u00e3o horizontal, colocar em ambas as extremidades um peso de ~1Kg para ver se a for\u00e7a sentida pelo sensor \u00e9 a mesma Apesar de n\u00e3o ser exatamente a mesma, as diferen\u00e7as n\u00e3o sao significativas nem apresentam um padr\u00e3o Obviamente o torque sentido pelo sensor \u00e9 inverso quando colocamos o objeto do lado contr\u00e1rio da t\u00e1bua","title":"Teste de COG no robot real"},{"location":"logbook/#teste-de-correcao-do-gripper","text":"Em cada 1 das 70 posi\u00e7\u00f5es de writs_1 e wrist_2 fazer o wrist_3 girar em 360 e obter os resultados obtidos com o modelo te\u00f3rico Nas mesmas 70 posi\u00e7\u00f5es obter os resultados obter os resultados com o robot real com gripper e um payload de 1.5Kg Fazer um merge e criar um modelo de corre\u00e7\u00e3o, sendo que em cada posi\u00e7\u00e3o do robot real, o valor de for\u00e7a deve ser 0","title":"Teste de Corre\u00e7\u00e3o do Gripper"},{"location":"logbook/#1903-reuniao","text":"Continuar","title":"19/03 - Reuni\u00e3o"},{"location":"logbook/#2303-irislab","text":"","title":"23/03 - IRISLab"},{"location":"logbook/#teste-correcao-do-sensor-ft","text":"Pasta F-Wrench 70 posi\u00e7\u00f5es reduzidas para 57 por causa de duplicados (180 = -180) e posi\u00e7\u00f5es imposs\u00edveis de posicionar o robot (colis\u00f5es) Teste Correct | Wrist_1 {0 - 135, 45} | Wrist_2 {0 - 135, 45} TCx_w1_w2 Teste das 57 posi\u00e7\u00f5es sem gripper e Payload 0kg Resultado - Maioria destes testes inutiliz\u00e1veis devido a uma atenua\u00e7\u00e3o dos valores das curvas por motivos desconhecidos Alguns testes com gripper com valores inutiliz\u00e1veis devido \u00e0 press\u00e3o feita pelo cabo do gripper nas posi\u00e7\u00f5es mais extremas","title":"Teste Corre\u00e7\u00e3o do Sensor FT"},{"location":"logbook/#2403-irislab","text":"A raz\u00e3o pela qual os testes anteriores estavam a apresentar uma atenua\u00e7\u00e3o nos valores das curvas devese ao facto da fila que guardava os valores de for\u00e7a estar a aumentar de tamanho, para o sobro a cada teste","title":"24/03 - IRISLab"},{"location":"logbook/#teste-correcao-gripper-repeat","text":"Pasta F-Wrench 70 posi\u00e7\u00f5es reduzidas para 57 por causa de duplicados (180 = -180) e posi\u00e7\u00f5es imposs\u00edveis de posicionar o robot (colis\u00f5es) Teste Correct | Wrist_1 {0 - 135, 45} | Wrist_2 {0 - 135, 45} TCx_w1_w2 Teste das 57 posi\u00e7\u00f5es sem gripper e Payload 0kg TCG_w1_w1 Teste das 57 posi\u00e7\u00f5es com gripper e Payload 1.5kg (sem cabo) Resultado Testes sem gripper tem diverg\u00eancias muito pequenas entre si, sendo poss\u00edvel extrair uma curva m\u00e9dia de todos os testes sendo que o m\u00e1ximo de erro que poder\u00e1 existir ser\u00e1 de 1.5N Tests com gripper apresentam diverg\u00eancias entre si muito maiores, sendo que para utilizar estes dados num modelo de corre\u00e7\u00e3o ter\u00edamos que adicionar a orienta\u00e7\u00e3o do gripper","title":"Teste Corre\u00e7\u00e3o Gripper (Repeat)"},{"location":"logbook/#2503-irislab","text":"","title":"25/03 - IRISLab"},{"location":"logbook/#modelo-de-correcao-do-sensor-ft","text":"Retirar a m\u00e9dia dos testes sem gripper Corrigir os testes com gripper com a curva m\u00e9dia dos testes sem gripper e guardar os valores resultantes numa matriz Utilizar esses valores para corrigir o sensor tendo em conta que a orienta\u00e7\u00e3o do end effector tem que entrar na equa\u00e7\u00e3o","title":"Modelo de Corre\u00e7\u00e3o do Sensor FT"},{"location":"logbook/#bags-de-corecao-com-e-sem-gripper","text":"correct_no_gripper_px.bag - 5 bags sem gripper nas 5 posi\u00e7\u00f5es deafult correct_gripper_px.bag - 5 bags com gripper nas 5 posi\u00e7\u00f5es default Em cada bag o robot posiciona-se na posi\u00e7\u00e3o indicada e roda o wrist_3 em 360 Erro - bags apenas gravaram /wrench e n\u00e3o /joint_states - Inutiliz\u00e1vel","title":"Bags de Core\u00e7\u00e3o com e sem gripper"},{"location":"logbook/#setup-kinect-para-detecao-de-gestos","text":"http://wiki.ros.org/mit-ros-pkg/KinectDemos/HandDetection","title":"Setup Kinect para dete\u00e7\u00e3o de gestos"},{"location":"logbook/#2603-irislab","text":"","title":"26/03 - IRISLab"},{"location":"logbook/#pesquisa-relativa-a-controlo-por-gestos","text":"Muita utiliza\u00e7\u00e3o de leap motion controllers Kinect muito utilizada para gestos com o corpo todo","title":"Pesquisa relativa a controlo por gestos"},{"location":"logbook/#melhoramento-da-geracao-de-varias-posicoes-para-o-end-effector","text":"Cada valor de wrist_1 tem agora uma cor associada para ser mais facil fazer a distin\u00e7\u00e3o","title":"Melhoramento da gera\u00e7\u00e3o de v\u00e1rias posi\u00e7\u00f5es para o end effector"},{"location":"logbook/#controlo-do-gripper-atraves-de-forca","text":"Controlo simples por peso - Funciona Controlo por eixo - Funciona For\u00e7a no X fecha For\u00e7a no Y abre Controlo quando lida com objetos - Funciona +/- Vari\u00e1vel est\u00e1 a agarrar algo? Pois apenas o controlo por for\u00e7a ns eixos fica desiquilibrado quando o robot est\u00e1 a agarrar algo Quando est\u00e1 a agarrar algo, a maneira de abrir o gripper tem que ser diferente Quando mede uma for\u00e7a no sentido contr\u00e1rio \u00e0 orienta\u00e7\u00e3o do gripper - Funciona Quando mede um peso pr\u00f3ximo de zero - Funciona +/- (objetos mais pesados) Problema de quando pega em objetos mais leves Problema do utilizador fazer uma for\u00e7a sobre o objeto que n\u00e3o fa\u00e7a o valor de peso passar pelo threshold Problema de quando dar reset ao sensor Periodicamente quando for observ\u00e1vel que nada est\u00e1 a interagir com o robot, e que n\u00e3o tem nenhum objeto agarrado","title":"Controlo do Gripper atrav\u00e9s de For\u00e7a"},{"location":"logbook/#3003-irislab","text":"","title":"30/03 - IRISLab"},{"location":"logbook/#modelo-de-correcao-do-sensor-ft_1","text":"Necessidade de uma matriz que relacione os valores das v\u00e1rias posi\u00e7\u00f5es do end effector Cada teste apenas d\u00e1 os valores de corre\u00e7\u00e3o relativos \u00e0 posi\u00e7\u00e3o da junta wrist_3 Para criar um modelo que possa corrigir os valores em qualquer orienta\u00e7\u00e3o \u00e9 preciso algo que relacione as orienta\u00e7\u00f5es TCG_correct Teste das 57 posi\u00e7\u00f5es em que a cada itera\u00e7\u00e3o o robot \u00e9 posicionado numa posi\u00e7\u00e3o default [0, -90, 0, 0, 0, 0] \u00c9 feito o zero_ft_sensor() O robot move-se para a dada posi\u00e7\u00e3o e o valor de for\u00e7a \u00e9 medido Resultado - \u00c9 not\u00e1vel a diferen\u00e7a de valores de for\u00e7a que existe entre a posi\u00e7\u00e3o default e cada uma das posi\u00e7\u00f5es, e estas diferen\u00e7as teram que ser contabilizadas no modelo de corre\u00e7\u00e3o","title":"Modelo de Corre\u00e7\u00e3o do Sensor FT"},{"location":"logbook/#3103-irislab","text":"","title":"31/03 - IRISLab"},{"location":"logbook/#controlo-por-gestos","text":"Segmenta\u00e7\u00e3o da point cloud vinda da kinect utilizando primeiro um cropbox, facilitado por uma bounding box, em que apenas se visualiza a mesa Utiliza\u00e7\u00e3o de Euclidean Clustering para segmentar a nova cloud, obtendo apenas 2 clusters que correspondem \u00e0s m\u00e3os / bra\u00e7os viewer.cpp","title":"Controlo por gestos"},{"location":"logbook/#0504-irislab","text":"","title":"05/04 - IRISLab"},{"location":"logbook/#modelo-de-correcao-do-sensor-ft_2","text":"Incluir a fun\u00e7\u00e3o de reset Utilizar numa fase inicial a m\u00e9dia das curvas com gripper Cria\u00e7\u00e3o de um conjunto de vetores correspondentes a cada uma das 56 posi\u00e7\u00f5es para compara\u00e7\u00e3o com a orienta\u00e7\u00e3o corrente do EE VERIFICAR TESTES DAS 56 POSI\u00c7\u00d5ES COM GRIPPER E VERIFICAR POSS\u00cdVEIS ERROS Divis\u00e3o do wrench.py em filter.py (filtro de m\u00e9dia com janela de 30 valores) e record.py (programa que move o wrist_3 de -180 a 180 e guarda os valores do sensor FT)","title":"Modelo de Corre\u00e7\u00e3o do Sensor FT"},{"location":"logbook/#0604-irislab","text":"","title":"06/04 - IRISLab"},{"location":"logbook/#testes-nas-56-posicoes-com-gripper-e-payload-0","text":"Comparar com os testes \"sem gripper\" e \"com gripper e payload 1.5\" para tentar chegar a uma conclus\u00e3o Melhoramento do programa record.py para garantir que os valores de for\u00e7a s\u00e3o corretamente gravados em cada posi\u00e7\u00e3o do wrist_3","title":"Testes nas 56 posi\u00e7\u00f5es com Gripper e Payload 0"},{"location":"logbook/#0704-irislab","text":"","title":"07/04 - IRISLab"},{"location":"logbook/#modelo-de-correcao-do-sensor-ft_3","text":"Seja qual for o payload, pode-se considerar como curvas de corre\u00e7\u00e3o as curvas obtidas em testes onde o EE est\u00e1 verticalmente alinhado com o ambiente, ou seja, ao rodar o wrist_3, nenhuma for\u00e7a dever\u00e1 ser exercida sobre os 3 eixos XYZ em qualquer posi\u00e7\u00e0o de wrist_3 Curva de corre\u00e7\u00e3o feita atrav\u00e9s das posi\u00e7\u00f5es de indices 2, 6, 34 e 38 (Posi\u00e7\u00f5es onde o EE est\u00e1 verticalmente orientado) Grava\u00e7\u00e3o de testes com o modelo te\u00f3rico para compara\u00e7\u00e3o com os testes reais","title":"Modelo de Corre\u00e7\u00e3o do Sensor FT"},{"location":"logbook/#neste-momento-exitem-4-tipos-de-curvas","text":"Curva de corre\u00e7\u00e3o posicional do Wrist3 (proveniente da m\u00e9dia das curvas das posi\u00e7\u00f5es de indices 2, 6, 34, 38) Curva de teste das 56 posi\u00e7\u00f5es com gripper e Payload 1.5Kg Curva de teste das 56 posi\u00e7\u00f5es com gripper e Payload 0Kg Curva de teste das 56 posi\u00e7\u00f5es provenientes do modelo te\u00f3rico Implementa\u00e7\u00e3o da fun\u00e7\u00e3o reset com o modelo de corre\u00e7\u00e3o","title":"Neste momento exitem 4 tipos de curvas"},{"location":"logbook/#1204-irislab","text":"GUI em GTK para os servi\u00e7os do iris_sami","title":"12/04 - IRISLab"},{"location":"logbook/#1304-irislab","text":"","title":"13/04 - IRISLab"},{"location":"logbook/#modelo-de-correccao-do-sensor-ft","text":"Fazendo a comprara\u00e7\u00e3o entre as curvas do teste te\u00f3rico com as curvas com payload 0, vemos que existe um padr\u00e3o entre as diferen\u00e7as do 2 testes Em X, se diminuirmos a amplitude do modelo te\u00f3rico em +/- 10%, aproximamos os modelo te\u00f3rico aos valores reais Em Y, se aumentarmos a amplitude do modelo te\u00f3rico em +/- 10% aproximamos o model te\u00f3rico aos valores reais Em Z, as diferen\u00e7as s\u00e3o causadas por outros fatores, pois o modelo te\u00f3rico, nos testes executados \u00e9 sempre 0 Necessita de outro tipo de corre\u00e7\u00e3o - tamb\u00e9m divido \u00e0 for\u00e7a com que \u00e9 acopulado o gripper ao EE Modelo completamente implementado no programa correct.py Corrige possicionalemnte com o angulo do wrist_3 Corrige orientacionalmente com o modelo te\u00f3rico Fun\u00e7\u00e3o de reset implementada nas 2 fases","title":"Modelo de Correc\u00e7\u00e3o do Sensor FT"},{"location":"logbook/#correcoes-finais-ao-modelo","text":"Corrigir modelo te\u00f3rico com os resultados obtidos Obter um valor (os tais +/- 10%) para corrigir o modelo te\u00f3rico Testes inicias com simples m\u00e9dias das diferen\u00e7as X = 0.846 e Y = 1.115 Possibilidade de obter melhores resultados com metodo dos m\u00ednimos quadrados Corrigir o eixo Z Fazer um test onde se fa\u00e7a variar o EE em torno de X ou Y de forma a obter os valores reais de Z Comparar com o modelo te\u00f3rico Obter o offset criado pela for\u00e7a com que se apertou o gripper Obter o desvio de amplitude provavelmente existente (tal como X e Y) Corrigir o drift","title":"Corre\u00e7\u00f5es finais ao Modelo"},{"location":"logbook/#1504-irislab","text":"","title":"15/04 - IRISLab"},{"location":"logbook/#modelo-de-correcao-do-sensor-ft_4","text":"Antes de aplicar os fatores de corre\u00e7\u00e3o Mean Mean - [ 1.30804571 1.50272948 1.576232 ] Mean Std - [ 0.34988912 0.50012359 0.46279643] Mean Max - [ 2.24789183 2.51883549 3.06942575] Std Mean - [ 0.81536524 0.93259604 0.99550626] Std Std - [ 0.2548648 0.31685171 0.33100798] Std Max - [ 1.41419107 1.48037816 1.6792048 ] Max Mean - [ 2.92629354 3.01282345 3.47414803] Max Std - [ 0.86005843 0.99741032 0.9491934 ] Max Max - [ 4.6716544 4.6230199 5.58771009] Necess\u00e1rio fazer mais testes para corrigir Z Z parece ser afetado diretamente por X Utilizando o mesmo fator de corre\u00e7\u00e3o que em X ( -0.154 ) Ap\u00f3s aplicar o fator de corre\u00e7\u00e3o em XYZ Mean Mean - [ 0.6251545 0.59968417 0.61334835] Mean Std - [ 0.30244126 0.32259647 0.26306484] Mean Max - [ 1.5099673 1.38590574 1.27972879] Std Mean - [ 0.33315744 0.24697093 0.32907034] Std Std - [ 0.08915038 0.09833696 0.10477162] Std Max - [ 0.75 0.75 0.67033111] Max Mean - [ 1.52328022 1.1413761 1.48248086] Max Std - [ 0.41916193 0.39568526 0.40593537] Max Max - [ 2.56008408 2.00279845 2.24928167] Z tamb\u00e9m \u00e9 afetado por um fator proporcional ao Nevess\u00e1rio fazer mais testes isoladamente ao eixo Z para o encontrar","title":"Modelo de Corre\u00e7\u00e3o do Sensor FT"},{"location":"logbook/#1604-reuniao","text":"","title":"16/04 - Reuni\u00e3o"},{"location":"logbook/#modelo-de-corrrecao-do-sensor-ft","text":"Testes isolados ao eixo Z Fixar o wrist_3 numa posi\u00e7\u00e3o e fazer rodar o wrist_2 sobre um dos eixos Y ou X Resultado - Fator de corre\u00e7\u00e3o de Z = 1.230 Todos os fatores t\u00eam que ser melhorados com o metodo dos quadrados minimos \u00c9 necess\u00e1rio criar um conjunto de testes de treino, onde se iram retirar os fatores de corre\u00e7\u00e3o e um cojunto de testes de valida\u00e7\u00e3o onde os parametros possam ser testados Os fatores de corre\u00e7\u00e3o devem ser referentes tanto aos exos isolados como entre eixos (XZ ou YZ) At\u00e9 agora os fatores de corre\u00e7\u00e3o obtidos com m\u00e9dias de diferen\u00e7as retiradas das observa\u00e7\u00f5es s\u00e3o theory[:,z] += theory[:,x] * 0.154 theory[:,x] = theory[:,x] * 0.846 theory[:,y] = theory[:,y] * 1.115 theory[:,z] = theory[:,z] * 1.230","title":"Modelo de Corrre\u00e7\u00e3o do Sensor FT"},{"location":"logbook/#controlo-do-gripper-atraves-de-forcas","text":"Cria\u00e7\u00e3o do vetor peso para atribuir a\u00e7oes ao gripper beaseadas nesse vetor","title":"Controlo do Gripper atrav\u00e9s de For\u00e7as"},{"location":"logbook/#tarefas_3","text":"Controlo do Robot pelos movimentos de for\u00e7a Fazer com que quando o robot pegue numa pe\u00e7a, isole o peso dela, para que as for\u00e7as sentidas sejam utilizadas para controlar o seu movimento Real time motion planning","title":"Tarefas"},{"location":"logbook/#1904-irislab","text":"Refactor do modelo te\u00f3rico","title":"19/04 - IRISLab"},{"location":"logbook/#controlo-do-gripper-atraves-de-forcas_1","text":"Utiliza\u00e7\u00e3o do vetor peso para que em conjunto com o vetor gravidade controlar a a\u00e7ao do gripper largar um objeto","title":"Controlo do Gripper atrav\u00e9s de For\u00e7as"},{"location":"logbook/#2004-irislab","text":"","title":"20/04 - IRISLab"},{"location":"logbook/#controlo-do-robot-atraves-de-forcas","text":"Direct communication with robot RTDE - https://www.universal-robots.com/articles/ur/interface-communication/real-time-data-exchange-rtde-guide/ URScript through socket - https://www.zacobria.com/universal-robots-zacobria-forum-hints-tips-how-to/script-via-socket-connection/ ur_rtde - https://sdurobotics.gitlab.io/ur_rtde/ Inverse Kinematics MovIt - http://docs.ros.org/en/melodic/api/moveit_tutorials/html/doc/robot_model_and_robot_state/robot_model_and_robot_state_tutorial.html Jacobian - https://www.rosroboticslearning.com/jacobian#:~:text=Jacobian%20is%20Matrix%20in%20robotics,(%20)%20of%20a%20robot%20manipulator.&text=Each%20column%20in%20the%20Jacobian,variation%20in%20each%20joint%20velocity Orocos KDL - https://www.orocos.org/wiki/orocos/kdl-wiki.html","title":"Controlo do Robot atrav\u00e9s de For\u00e7as"},{"location":"logbook/#2104-irislab","text":"","title":"21/04 - IRISLab"},{"location":"logbook/#jacobian-theory","text":"Introduction to jacobian matrix Move it robot state, ik and jacobian tutorial made Start experimenting with movements in simulated ur10e (gazebo). Problems Gazebo s\u00f3 publica o estado do robot a 50Hz, ou seja, o ciclo de calculo de juntas do robot apenas pode correr num m\u00e1ximo de 50Hz Gazebo apenas aceita controlo de movimento atrav\u00e9s de valores de juntas, ou seja, requer o moveit para enviar valores de juntas -> mais lento Enviar movimento sincronamente faz com que o movimento do robot seja aos solavancos, pois, entre cada movimento h\u00e1 o tempo de calculo do proximo Enviar movimentos assincronamente funciona mas \u00e9 necess\u00e1rio encontrar a frequencia certa/\u00f3tima para enviar os movimentos, senao o robot \"encrava\"","title":"Jacobian Theory"},{"location":"logbook/#2204-irislab","text":"","title":"22/04 - IRISLab"},{"location":"logbook/#jacobian-simulation","text":"Envio de valores de juntas asincronamente ao robot atrav\u00e9s do moveit Maioria dos movimentos s\u00e3o flu\u00eddos mas h\u00e1 certas posi\u00e7\u00f5es onde o robot \"falha\" em calcular a trajetoria Ou por exceder o limite das juntas Ou por exceder o limite de alcance Ou por nao conseguir mesmo se mover nessa dada dire\u00e7\u00e3o H\u00e1 a necessidade de controlar as juntas do robot por velocidade em ves de por posi\u00e7\u00e3o","title":"Jacobian Simulation"},{"location":"logbook/#2304-irislab","text":"","title":"23/04 - IRISLab"},{"location":"logbook/#jacobian-real-ur10e","text":"O controlador funciona um pouco melhor pois os valores das juntas s\u00e3o publicados a 500Hz Ainda h\u00e0 alguns solavancos, mas s\u00e3o muito suaves Controlador integrado com o peso calculado para que o robot se mova na dire\u00e7\u00e3o que est\u00e1 a ser empurrado Resultados positivos Apenas h\u00e1 numa diferen\u00e7a na velocidade com que o EE se move dependendo da for\u00e7a que esta a ser execida e da sua posi\u00e7\u00e3o Pode ser resolvido efetuando o controlo das juntas por velocidade","title":"Jacobian Real UR10e"},{"location":"logbook/#2604-irislab","text":"","title":"26/04 - IRISLab"},{"location":"logbook/#urscript-and-rtde-interfaces","text":"Envio de instrucoes em URScript para o Robot atrav\u00e9s de sockets pela interface Real-Time 30003 Tentativa de utiliza\u00e7\u00e3o do pacote pip python-urx mas \u00e9 prefer\u00edvel enviar os comandos manualmente Robot recebe e executa bem as intru\u00e7\u00f5es Falta testar a velocidade com que se consegue interagir com o robot Utiliza\u00e7\u00e3o da bilblioteca C++ ur_rtde para interagir com o robot Bilbioteca muito completa com muitas funcionalidades No entanto o robot apenas suporta uma liga\u00e7\u00e3o \u00e0 porta 30004 simultaneamente o que significa que o driver n\u00e3o pode estar ligado, pois este tambem usa a interface RTDE","title":"URScript and RTDE Interfaces"},{"location":"logbook/#2704-irislab","text":"","title":"27/04 - IRISLab"},{"location":"logbook/#urdriver-mais-recente","text":"Experimenta\u00e7\u00e3o da versao mais recente do ur_robot_driver que contem controladores de velocidade Tanto controladores poderosos em PID como os de posi\u00e7\u00e3o, tal como um controlador direto de velocidade das juntas do robot","title":"URDriver mais recente"},{"location":"logbook/#2804-irislab","text":"","title":"28/04 - IRISLab"},{"location":"logbook/#ursim-em-virtual-machine","text":"Simulador oficial do UR10e que providencia todas as interfaces e funcionalidades do robot real (excepto controlos por for\u00e7a) Aceita comandos URScript Boa plataforma para testes de intera\u00e7\u00e3o com o robot","title":"URSim em Virtual Machine"},{"location":"logbook/#3004-reuniao","text":"","title":"30/04 - Reuni\u00e3o"},{"location":"logbook/#jacobian-weight-real-ur10e","text":"Testes com v\u00e1rios parametros de controlo assincrono da posi\u00e7\u00e3o do robot Comportamento actual \u00e9 aceit\u00e1vel na medida em que as trajetorias calculadas s\u00e3o precisas No entanto existe delay, a velocidade \u00e9 muito lenta, e \u00e9 necess\u00e1rio ser adaptada \u00e0 for\u00e7a que se faz (quanto mais for\u00e7a, mais r\u00e1pido) Necess\u00e1rio incorporar movimentos rotacionais utilizado o torque","title":"Jacobian Weight Real UR10e"},{"location":"logbook/#multiple-control-interfaces","text":"","title":"Multiple Control Interfaces"},{"location":"logbook/#reuniao","text":"Necessidade de implementar controlador com velocidades de juntas Implementar movimentos angulares com os valores de torque Fazer o robot pegar em algo e depois move-lo com a for\u00e7a Dar reset no peso quando o robot pega em algo (dar um X tempo de calibra\u00e7\u00e3o) Implementar double-tap Tentar distinguir entre mover o EE e pegar numa pe\u00e7a (rela\u00e7\u00e3o torque / for\u00e7a)","title":"Reuni\u00e3o"},{"location":"logbook/#0505-irislab","text":"","title":"05/05 - IRISLab"},{"location":"logbook/#movimentos-angulares-com-os-valores-de-torque","text":"Tentativa de traduzir valores de torque sentido no sensor FT (tool0) em rota\u00e7\u00f5es globais (world) Cria\u00e7\u00e3o de um TF (torque) que traduz uma rota\u00e7\u00e3o do tool0 no eixo do torque sentido no sensor Obter a diferen\u00e7a de rota\u00e7\u00e3o dos 2 transforms e usar essa rota\u00e7\u00e3o Problema - Apenas consegui obter a rota\u00e7\u00e3o do TF \"torque\" em rela\u00e7\u00e3o ao TF \"original\" https://answers.ros.org/question/42289/difference-between-two-rigid-body-transformations/","title":"Movimentos angulares com os valores de torque"},{"location":"logbook/#1005-irislab","text":"","title":"10/05 - IRISLab"},{"location":"logbook/#movimentos-angulares-com-os-valores-de-torque_1","text":"Consegui obter a rota\u00e7\u00e3o global dos 2 TFs Foi necess\u00e1rio fazer a multiplica\u00e7\u00e3o dos TFs utilizando os seus inversos, para que assim o resultado seja em rela\u00e7\u00e3o ao world Ou seja Rot = Inv(Inv(TFtq)) * Inv(TFft) = TFtq * Inv(TFft) Para mais info -> torque_to_angvel.cpp","title":"Movimentos angulares com os valores de torque"},{"location":"logbook/#1105-irislab","text":"Refactor da disposi\u00e7\u00e3o de todos os n\u00f3s Cria\u00e7\u00e3o de n\u00f3s especificos para velocidades lineares e angulares Cria\u00e7\u00e3o de fatores para traduzir for\u00e7a / torque em velocidade","title":"11/05 - IRISLab"},{"location":"logbook/#1305-reuniao","text":"Continuar","title":"13/05 - Reuni\u00e3o"},{"location":"logbook/#1705-irislab","text":"","title":"17/05 - IRISLab"},{"location":"logbook/#controlar-as-juntas-por-velocidade","text":"Comandos URScript por TCP para a porta 30003 Comando speedj n\u00e3o apresenta bom funcionamento, cada vez que se envia um comando novo, o anterior para abruptamente Bilioteca UR_RTDE Comandos de velocidade funcionam corretamente e \u00e0 frequencia de 500Hz N\u00e3o \u00e9 poss\u00edvel utilizar esta bilbioteca em paralelo com o driver ROS Novo driver ROS Controlador de velocidade de juntas aparenta funcionar bem Apenas testado em URSim","title":"Controlar as juntas por Velocidade"},{"location":"logbook/#1805-irislab","text":"","title":"18/05 - IRISLab"},{"location":"logbook/#controlar-as-juntar-por-velocidade","text":"Comandos URScript por TCP para a porta 30003 Nenhuma combina\u00e7\u00e3o de parametros de speedj funcionou corretamente O problema sendo que a cada novo comando urscript enviado, o anterior para abruptamente Teste com servoj que seria o comando apropriado para movimentos continuos / RT tambem nao deu resultados O robot claramente movia-se aos solavancos No entanto a interface real-time pode ser util na prespectiva de read-only para um programa de monitorament A porta 30003 esta ativa e envia informa\u00e7\u00e3o a 500Hz independentemente do modo de opera\u00e7\u00e3o do robot Biblioteca UR_RTDE Movimentos suaves e continuos a 500Hz Continua a nao haver a possibilidade de utiliza\u00e7\u00e3o em paralelo com o driver Possibilidade de utiliza\u00e7\u00e3o em Remote Control ou atravez do urcap de external control Necessidade de ser compilada manualmente para obter a vers\u00e3o mais recente Novo driver ROS Testado no robot real com a utiliza\u00e7\u00e3o \"obrigatoria\" do external_control.urcap Movimentos suaves, no entanto aparentam ausencia de controlador pois o robot, assim que lhe \u00e9 enviado um comando de velocidade, aparenta ganhar essa velocidade instantaneamente ao inves de progressivamente Tarefas Comparar UR_RTDE com o novo driver ROS a n\u00edvel de Suavidade das trajet\u00f3rias Estabilidade Delay no envio de comandos Isolar todo o sistema o mais poss\u00edvel do driver / moveit Fechar o sistema mesmo com o controlador em posi\u00e7\u00e3o utilizando o moveit","title":"Controlar as juntar por Velocidade"},{"location":"logbook/#1905-irislab","text":"","title":"19/05 - IRISLab"},{"location":"logbook/#sistema-fechado-utilizando-controlo-de-posicao-pelo-moveit","text":"Calculo de velocidades funciona bem (jacobian) Controlador posicional moveit funciona bem se for aplicada uma for\u00e7a constante Funciona mal ao parar, pois para abruptmanete devido aos limites superiores e inferiores de for\u00e7a Funciona muito mal quando \u00e9 aplicada uma for\u00e7a baixa e constante, pois estando perto dos limites definidos, o controlo fica a oscilar entre 0 e o limite Outra raz\u00e3o, \u00e9 que para calcular um novo valor de juntas, \u00e9 necess\u00e1rio o valor presente, e n\u00e3o h\u00e1 possibilidade de saber a precis\u00e3o com que esse valor \u00e9 obtido Solu\u00e7\u00e3o Suavizar os comandos de velocidade (controlador a s\u00e9rio ou um filtro de m\u00e9dia) Controlar o robot diretamente por velocidade Ou pela interface RTDE diretamente Ou com o driver novo que tem controladores de velocidade","title":"Sistema Fechado utilizando controlo de Posi\u00e7\u00e3o pelo MoveIt"},{"location":"logbook/#novo-driver","text":"Cria\u00e7\u00e3o de um ws novo onde dou merge de todas as funcionalidades com a vers\u00e3o mais recente do driver ROS do UR10e que j\u00e1 implementa controladores de velocidade At\u00e9 agora, tanto o moveit, como iris_sami e controlo por velocidade aparenta funcionar Falta testar todos o iris_cobot","title":"Novo Driver"},{"location":"logbook/#2005-irislab-reuniao","text":"","title":"20/05 - IRISLab / Reuni\u00e3o"},{"location":"logbook/#controlo-por-velocidade-no-driver-novo","text":"O controlador scaled_vel_joint_traj_controller nao funciona como esperado Ele nao envia um conjunto de velocidades \u00e0s juntas Ele recebe uma trajetoria contendo posicoes e velocidades e assim, controla o robot https://forum.universal-robots.com/t/ur5-constant-motion/14305 Programa scaled_vel_controller que cria trajetorias e as envia para o robot baseado no exemplo do ur_modern_driver https://github.com/ros-industrial/ur_modern_driver/blob/master/test_move.py O mais prov\u00e1vel \u00e9 vir a usar o joint_group_vel_controller Utiliza\u00e7\u00e3o do joint_vel_group_controller para enviar os valores de velocidade \u00e0s juntas Utiliza\u00e7\u00e3o de um filtro de m\u00e9dia com uma sliding window de 50 Movimentos lineares muito suaves e requerem pouca for\u00e7a Movimetos rotacionais apresentam muitas oscila\u00e7\u00f5es e a dada altura o robot gaha um comportamento de feedback em que se nao largarmos o gripper ele aumenta e fica \"agressivo\" Necessidade de tornar este controlador mais complexo (pid ou um filtro diferente)","title":"Controlo por Velocidade no Driver novo"},{"location":"logbook/#2605-irislab","text":"","title":"26/05 - IRISLab"},{"location":"logbook/#forks-do-novo-driver-e-descricao","text":"Descri\u00e7\u00e3o - https://github.com/fabioalves98/universal_robot/tree/calibration_devel Driver - https://github.com/fabioalves98/Universal_Robots_ROS_Driver Pequenas altera\u00e7\u00f5es aos pacotes para utiliza,\u00e3o com o UR10e do iries","title":"Forks do Novo Driver e Descri\u00e7\u00e3o"},{"location":"logbook/#teste-de-movimentos-com-objetos-pesados","text":"Testes com pesos de 1Kg e 2Kg e payload 0 Kg definido da dashboard Movimentos com o peso de 1Kg funcionam perfeitamente Movimentos com o peso de 2Kg funcionam bem, mas alguma trajet\u00f3rias, apresentam solavancos... Provavelment devido ao calculo dos movimentos feito pelo robot nao acontar com o novo peso","title":"Teste de movimentos com objetos pesados"},{"location":"logbook/#2805-irislab","text":"","title":"28/05 - IRISLab"},{"location":"logbook/#detecao-de-double-tap-no-gripper","text":"Integra\u00e7\u00e3o dos valores de for\u00e7a provenientes diretamente do /wrench Avalia\u00e7\u00e3o dos valores e escolha dos melhores parametros que permitam identificar um toque r\u00e1pido e distinguir de um toque normal Valor de diferen\u00e7\u00e3o m\u00ednima de 5N Distanca temporal minima entre toques - 100ms Distancia temporal maxima entre toques - 400ms Quando o n\u00f3 double_tap deteta um double tap, chama o servi\u00e7o de gripper_toggle","title":"Dete\u00e7\u00e3o de Double tap no gripper"},{"location":"logbook/#0106-irislab","text":"Review","title":"01/06 - IRISLab"},{"location":"logbook/#0206-irislab","text":"","title":"02/06 - IRISLab"},{"location":"logbook/#maquina-de-estados-do-gripper","text":"Modo de intera\u00e7\u00e3o com o bra\u00e7o em que num estado inicial ele se move consoante as for\u00e7as sentidas, mas ap\u00f3s uma ac\u00e3o de double tap, o gripper fecha-se, o programa calcula o peso do objeto agarrado, compensa esse peso, e permite ao utilizador mover o bra\u00e7o com o objeto acopulado, exercendo as mesmas for\u00e7as de anteriormente M\u00e1quina de estado inicial funcional, no entanto existem solavancos nas transi\u00e7\u00f5es de estados Necessidade de uma maquina de estado geral que controla os n\u00f3s de movimento, para que eles possam ser parados / resumidos entre as transi\u00e7\u00f5es de estado Necessidade de compensar os valores de torque","title":"M\u00e1quina de estados do Gripper"},{"location":"logbook/#0706-irislab","text":"","title":"07/06 - IRISLab"},{"location":"logbook/#teste-56-posicoes","text":"Necessidade de gravar os valores de torque para criar modelo de corre\u00e7\u00e3o an\u00e1logo ao que corrige os valores de for\u00e7a Testes TCW - Valores de for\u00e7a e torque em 57 posi\u00e7\u00f5es com gripper e payload 0Kg Testes TCWNG - Valores de for\u00e7a e torque em 8 posi\u00e7\u00f5es sem gripper e payload 0Kg","title":"Teste 56 posi\u00e7\u00f5es"},{"location":"logbook/#maquina-de-estados-global-ur10e","text":"","title":"M\u00e1quina de Estados Global UR10e"},{"location":"logbook/#inputs","text":"Double Tap X / Y / Z Finger Position","title":"Inputs"},{"location":"logbook/#funcionalidades","text":"Working - Task predefinida pelo utilizador Reactive Stop - Em movimento manuais / pre definidos se sentir uma for\u00e7a p\u00e1ra e espera por input Freedrive - Robot move-se na dire\u00e7\u00e3o da for\u00e7a sentida Para a existencia de um movimento mais preciso, talvez alterar a rela\u00e7\u00e3o for\u00e7a-velocidade em real time Fine Control - Velocidade de opera\u00e7\u00e3o muito reduzida Ou criar um modelo que compreenda v\u00e1rias rela\u00e7\u00f5es de for\u00e7a-velocidade mas que a transi\u00e7\u00e3o entre elas seja \"seemless\" Deliver Object - Robot entrega ao utlizador um objeto fazendo-o lagar quando o utilizar exerce for\u00e7a suficnete para suster o objeto Implementar esta funcionalidade futuramente no controlo do robot atrav\u00e9s de gestos (m\u00e3os) Lift and Control - Levar o gripper at\u00e9 um objeto, dar input para ele o agarrar, fazer com que o bra\u00e7o levante o objeto, compense o seu peso e continue em modo freedrive Custom Screw - Colocar o robot numa posi\u00e7\u00e3o e faze-lo apertar algo (rodando o wrist_3) at\u00e9 notar que est\u00e1 a exercer for\u00e7a suficiente Modo de Configura\u00e7\u00e3o - ?","title":"Funcionalidades"},{"location":"logbook/#controlo-das-luzes-do-gripper","text":"Defini\u00e7\u00e3o de fun\u00e7oes de controlo dos LEDS do gripper no iris_sami Possivel contorlar anima\u00e7\u00e3o, cor, velocidade e mudan\u00e7a de modos pr\u00e9-definidos","title":"Controlo das Luzes do Gripper"},{"location":"logbook/#0806-irislab","text":"","title":"08/06 - IRISLab"},{"location":"logbook/#modelo-de-correcao-de-torque","text":"Testes nas 57 posi\u00e7\u00f5es com gripper e grava\u00e7\u00e3o dos valores de torque Teses em 8 posi\u00e7\u00f5es sem gripper para efetuar a corre\u00e7\u00e3o dos valores do sensor consoante a posi\u00e7\u00e3o do wrist_3 Cria\u00e7\u00e3o do programa positional_correction.py que utiliza os 8 testes anteriores e cria 2 arrays (for\u00e7a e torque) para serem utilizados pelos n\u00f3s de correc\u00e7\u00e3o","title":"Modelo de Corre\u00e7\u00e3o de Torque"},{"location":"logbook/#1506-irislab","text":"","title":"15/06 - IRISLab"},{"location":"logbook/#modelo-teorico-de-correcao-de-torque","text":"Adcionar ao ficheiro ft_sensor.py a parte te\u00f3rica do torque baseado da seguinte f\u00f3rmula Testes nas 57 posi\u00e7\u00f5es ao simulador no modelo te\u00f3rico e grava\u00e7\u00e3o dos valores de torque Compara\u00e7\u00e3o dos testes reais com os te\u00f3ricos mostram que o modelo te\u00f3rico de torque est\u00e1 bem desenhado mas os parametros precisam de ser ajustados Necessidade de criar um modelo que crie os testes ao modelo te\u00f3rico analiticamente (sem simula\u00e7\u00e3o e grava\u00e7\u00e3o)","title":"Modelo Te\u00f3rico de Corre\u00e7\u00e3o de Torque"},{"location":"logbook/#2106-irislab","text":"","title":"21/06 - IRISLab"},{"location":"logbook/#modelo-de-correcao-de-torque_1","text":"Valores do modelo te\u00f3rico utilizados na parte de corre\u00e7\u00e3o dos valores reais Ap\u00f3s alguns testes, o modo compliance do robot funciona muito melhor Necessidade de atualizar o valor do centro de gravidade do modelo quando o robot pega em algo Implementa\u00e7\u00e3o de constantes de convers\u00e3o FT -> Velocidade atrav\u00e9s de parametros do servidro dynamic reconfigure Constante de divis\u00e3o de For\u00e7a e Torque Sensibilidade","title":"Modelo de Corre\u00e7\u00e3o de Torque"},{"location":"logbook/#2206-irislab","text":"","title":"22/06 - IRISLab"},{"location":"logbook/#modelo-teorico","text":"Atualiza\u00e7\u00e3o do centro de gravidade do objeto e calculo do torque te\u00f3rico baseado nesse valor (PODE N\u00c3O ESTAR FEITO DO MELHOR FORMA) Calculo feito atrav\u00e9s da soma do peso do gripper * cog do gripper e peso do objeto * cog do objeto (fingers) Peso do objeto \u00e9 retirado diretamente dos valores de for\u00e7a medidos pelo sensor Devido \u00e0 imprecis\u00e3o da compoente for\u00e7a do sensor, o peso calculado nem sempre corresponde ao peso real Neste momento, o peso calculado parece sempre que \u00e9 superior ao peso real em 1.2x Existe o problema de quanto maior o peso do objeto mais imprecisoes existem nos valores medidos e quanto aos movimentos, o robot ir\u00e1 ter mais dificuladade em executalos visto que at\u00e9 agora, o payload configurado na interface do robot \u00e9 de 0Kg em vez do peso real","title":"Modelo Te\u00f3rico"},{"location":"logbook/#resets-periodicos","text":"Programa time_series_analysis.py que analisa uma amostra de 100 valores provenientes de wrench_filtered e analisa atrav\u00e9s do desvio padr\u00e3o dos dados se existem for\u00e7as externas a interagir com o robot","title":"Resets Peri\u00f3dicos"},{"location":"logbook/#2506-bilbioteca","text":"Limpar reposit\u00f3rio e ter apenas um workspace ROS com o driver atualizado Cria\u00e7\u00e3o de uma interface rqt para iris sami Cria\u00e7\u00e3o de um site mkdocs para escrever documenta\u00e7\u00e3o dos programas","title":"25/06 - Bilbioteca"},{"location":"logbook/#2906-biblioteca","text":"rqt iris sami ready for use","title":"29/06 - Biblioteca"},{"location":"logbook/#3006-biblioteca","text":"Pull request iris-ua/iris_sami Pesquisa de estrutura para a tese","title":"30/06 - Biblioteca"},{"location":"logbook/#107-irislab","text":"","title":"1/07 - IRISLab"},{"location":"logbook/#interaction","text":"Componentes X, Y, Z do modulo double tap isoladas para permitir identificar v\u00e1rios tipos de toques no EE Em X, Y, Z e no sentido positivo e negativo permitindo 6 tipos diferentes de taps","title":"Interaction"},{"location":"logbook/#ur10e-state-machine","text":"Implementa\u00e7\u00e3o de uma maquina de estados semelhante \u00e0 anterior mas utilizancho a bilbioteca ros smach Cada estado \u00e9 uma classe isolada com uma fun\u00e7\u00e3o execute Integra\u00e7\u00e3o muito poderosa com ROS Possibilidade de visualizar o estado corrente da m\u00e1quina atrav\u00e9s de smach_viewer Fix no interface do gripper onde a chamada repetida das fun\u00e7\u00f5es get_state e get_pos gerava exce\u00e7\u00f5es HTTP Necessidade de dar fix \u00e0 maneira como interagir com o gripper","title":"UR10e State Machine"},{"location":"logbook/#707-irislab","text":"Altera\u00e7\u00e3o do servi\u00e7o /iris_sami/status para 2 t\u00f3picos /iris_sami/arm_status (500Hz) e /iris_sami/gripper_status (50Hz) Cria\u00e7\u00e3o de 2 inst\u00e2ncias de controlo do gripper dentro do server.py do iris_sami Cria\u00e7\u00e3o do n\u00f3 weight que calcula constantemente a magnitude da for\u00e7a exercida no sensor FT","title":"7/07 - IRISLab"},{"location":"logbook/#807-irislab","text":"","title":"8/07 - IRISLab"},{"location":"logbook/#modelo-teorico-de-correcao-de-torque_1","text":"C\u00e1lculo da segunda parte da equa\u00e7\u00e3o utilizando para cada eixo um plano perpendicular ao eixo, onde se ira projetar o vetor garvidade Ao inves de criar o plano utilizando o vetor gravidade e projetar o eixo Calculo do COG utilizando as medidas de for\u00e7a e torque Quando o gripper esta acopulado, as medidas de for\u00e7a e torque s\u00e3o 0 (ele est\u00e1 compensado) Inicialmente calcular o COG do gripper com medidas de for\u00e7a e torque -> guardar valores Depois, dinamicamnete, quando se pega num objeto, calcular peso e cog com medidas de for\u00e7a e torque -> atualizar o modelo Divis\u00e3o dos parametros de sensibilidade em for\u00e7a e torque","title":"Modelo Te\u00f3rico de Corre\u00e7\u00e3o de Torque"},{"location":"logbook/#1207-biblioteca","text":"","title":"12/07 - Biblioteca"},{"location":"logbook/#modelo-teorico-de-correcao-de-torque_2","text":"Gera\u00e7\u00e3o de poses correspondentes ao conjunto de 58 combina\u00e7\u00f5es de juntas para teste do modelo te\u00f3rico Lista de poses guradada em curves/poses_58.list Altera\u00e7\u00e3o do modelo te\u00f3rico para ser extens\u00edvel ao calculo de for\u00e7a e torque Cria\u00e7\u00e3o da fun\u00e7\u00e3o theoryFT que dada uma pose, calcula a for\u00e7a e o torque te\u00f3rica que um objeto com um dado peso e COG teria Altra\u00e7\u00e3o do programa plot.py que compara os testes reais com os te\u00f3ricos onde a cada compara\u00e7\u00e3o, um novo teste te\u00f3rico \u00e9 corrido, visto que temos conhecimentos das poses que foram utilizadas Altera\u00e7\u00e3o da equa\u00e7\u00e3o de gera\u00e7\u00e3o de torques no programa ft_theory.py Valores gerados teoricamente est\u00e3o muito mais pr\u00f3ximos dos valores reais e prontos para ser utilizados","title":"Modelo Te\u00f3rico de Corre\u00e7\u00e3o de Torque"},{"location":"logbook/#1407-biblioteca","text":"","title":"14/07 - Biblioteca"},{"location":"logbook/#scan-do-ambiente-externo-ao-robot","text":"Adi\u00e7\u00e3o dos xacros de uma orbec astra ao EE do robot Programa environment.cpp que guarda uma point cloud global correspondente ao ambiente Expoe um servi\u00e7o que quando chamado, recolhe um asample RGBD, recolhe o TF da camera e adiciona a sample ao ambiente de forma incremental Programa scan.py coordena os movimentos do robot e a chamada ao servi\u00e7o de take_sample","title":"Scan do Ambiente Externo ao Robot"},{"location":"logbook/#1607-irislab","text":"","title":"16/07 - IRISLab"},{"location":"logbook/#modelo-de-compensacao-de-torque","text":"Implementa\u00e7\u00e3o da atividade de pegar num objeto com a maquina de estado escrita em ros_smach Calculo do peso do objeto ainda precisa de ser melhorado Cria\u00e7\u00e3o de testes para calcular o COG do gripper e posteriormente do objeto","title":"Modelo de Compensa\u00e7\u00e3o de Torque"},{"location":"logbook/#2107-reuniao","text":"Finaliza\u00e7\u00e3o do tema de compensa\u00e7\u00e3o de for\u00e7a e torque Discuss\u00e3o do modo de transi\u00e7\u00e3o de estados da m\u00e1quina de estados do robot Discuss\u00e3o da melhor forma de abordar o tema de calculo de trajet\u00f3rias com obstaculos Discuss\u00e3o da estrutura do \u00edndice da tese","title":"21/07 - Reuni\u00e3o"},{"location":"logbook/#2307-bilbioteca","text":"Setup do ambiente Latex para a escrita do documento Primeira vers\u00e3o provis\u00f3ria do \u00ednidice da tese","title":"23/07 - Bilbioteca"},{"location":"related_work/","text":"State of The Art Research 1 - 2019 - Human\u2013robot interaction in industrial collaborative robotics: a literature review of the decade HRI - the process of conveying human intentions and interpreting task descriptions into a sequence of robot motions complying with robot capabilities and working requirements Criteria for HRI Workspace: the overlapping space in the working range of human and robot is described as the common workspace. Working time: it is defined as the time the participant is working inside the workspace. Aim: every entity of the interacting team has an aim to achieve. This aim can match or mismatch with the other one. Contact: since human and robot share the same workspace, they may come into contact with each other either [16] (i) occasionally or by accident if normal operation is intended to be without contact, or (ii) on purpose if the operator is supposed to work in contact with the robot, exchanging forces and cooperating in action upon on the environment. Classification of HRI Human\u2013Robot Coexistence (HRCx) , also called coaction, is defined [17] as the capability of sharing the dynamic workspace between humans and robots without a common task (operate on dissimilar tasks) [18,19] or, without requiring mutual contact or coordination of actions [20] and intentions (human and robot may have different aims) [21]. It is generally limited to collisions avoidance. Human\u2013Robot Cooperation (HRCp) acts on a higher level [22] than HRCx. In such a case, humans and robots are working on the same purpose and fulfill the requirements of time and space, simultaneously. The cooperation requires thus advanced technologies such as force-feedback sensing or advanced machine vision [1,17], and far more sensing techniques for collision detection and avoidance. Human\u2013Robot Collaboration (HRC) is the feature of performing a complex task with direct human inter-action in two different modalities [21]: (i) Physical collaboration where an explicit and intentional contact with forces exchange exists between human and robot [23]. By measuring or estimating these forces/torques [10], the robot can predict human motion intentions and react accordingly [24,25]. (ii) Contactless collaboration where no physical interaction exists. In such a case, actions are coordinated from information exchange which can be achieved via direct communication (speech, gestures, etc.), or indirect communication (intentions recognition, eye gaze direction, facial expressions, etc.) [26,27]. In such scenarios, the operator performs task parts requiring dexterity or decision-making, while the robot realizes parts that are not well suited to direct human involvement (repetitive or high-force applications, chemical deposition, precision placement, etc.) Boa tabela de compara\u00e7\u00e3o de artigos Safety in Industrial Robots Distributed real-time approach based on a 3D simulation [117] 121, 122, 123, 304 Real-time collision avoidance approach based on depth sensor [119] Pre-collision algorithms and virtual reality tools [154] Cap\u00edtulo com bu\u00e9 conteudo em refer\u00eancias Cognitive Human Robot Interactions Human actions recognition [192-194] Gestures recognition [201] Control interface to teleoperate robot based on hand gestures using ROS [304] Faces Recognition [202] Voice Commanding [206] Social gaze and social acceptance [195] Robot Programming Approaches Generation of Robotic Skills [216] Augmented and Virtual Reality [215] On-line Programming [217] Programming by Demonstration Muitas refer\u00eancias sobre ensinar robots a fazer tarefas apenas por demonstra\u00e7\u00e3o Human Robot Tasks Allocation Ontology-based Knowledge Simplify user interface [93, 222] Generic knowledge based system architecture for cobots [40] Creating high-level tasks plans Behavior Trees [228] CoSTAR framework [229] Skill Based System software in ROS [304] XRob platfoem for HRI [230] Architecture for interactive multi-modal industrial HRI [231] Tasks Allocation and Scheduling Decision-making method that allows human-robot task allocation integrated within ROS [197] Allocating tasks to humans and robots for cell manufactoring [235] Analytic Hirarchy Process as a decision-making approach and Hierarchical Task Analysis [324] Fault Tolerance Error Detection Error Diagnosis Recovery Papers Para Ler [7] - Human centered assistance applications for the working environment of the future. 2015 [14] - Evaluation of flexible graphical user interface for intuitive human robot interactions. 2014 [18] - Integration of active and passive compliance control for safe human-robot coexistence. 2009 [19] - A design approach for incorporating task coordination for human-robot coexistence within assembly systems. 2015 [21] - Integrated control for PHRI: collision avoidance, detection, reaction and collaboration. 2012 [22] - A brief review on safety strategies of physical human-robot interaction. 2019 [23] - A depth space approach for evaluating distance to objects. 2015 [24] - Multimodal control for human-robot cooperation. 2013 [27] - Planning safe and legible hand-over motions for human-robot interaction. 2010 [28] - Study on application of a human-robot collaborative system using hand-guiding in a production line. 2016 [44] - Ros based coordination of human robot cooperative assembly tasks. 2015 [49] - Human-robot physical interaction and collaboration using an industrial robot with a closed control architecture. 2013 [55] - Optimized assistive human\u2013robot interaction using reinforcement learning. 2016 [60] - Introducing robots without creating fear of unemployment and high cost in industries. 2018 [70] - Human-robot collaboration for tooling path guidance. 2016 [88] - Real-time computation of distance to dynamic obstacles with multiple depth sensors. 2016 [100] - Working together: a review on safe human-robot collaboration in industrial environments. 2017 [104] - Toward safe human robot collaboration by using multiple kinects based real-time human tracking. 2014 [117] - A real time distributed approach to collision avoidance for industrial manipulators. 2014 [119] - A depth space approach to human-robot collision avoidance. 2012 [124] - A general procedure for collision detection between an industrial robot and the environment. 2015 [167] - Cooperative tasks between humans and robots in industrial environments. 2012 [170] - Safety-aware trajectory scaling for human-robot collaboration with prediction of human occupancy. 2015 [190] - Design of a collaborative architecture for human-robot assembly tasks. 2017 [191] - A user-adaptive gesture recognition system applied to human-robot collaboration in factories. 2016 [192] - Action recognition for human robot interaction in industrial applications. 2015 [195] - A proposed gesture set for the control of industrial collaborative robots. 2012 [197] - On a human-robot collaboration in an assembly cell. 2017 [200] - Dynamic time warping for gesture-based user identification and authentication with kinect. 2013 [217] - Intuitive and model-based on-line programming of industrial robots: a modular on-line programming environment. 2008 [218] - Spatial programming for industrial robots through task demonstration. 2013 [221] - Human\u2013robot interaction review and challenges on task planning and programming. 2016 [229] - Costar: instructing collaborative robots with behavior trees and vision. 2017 [288] - How human-robot teamwork will upend manufacturing. 2014 [293] - Manual guidance for industrial robot programming. 2015 [310] - On a new generation of torque controlled light-weight robots. 2001 [319] - Collision-free motion planning for human-robot collaborative safety under cartesian constraint. 2018 [321] - Survey on human\u2013robot collaboration in industrial settings: safety, intuitive interfaces and applications. 2018 [325] - Key challenges and open issues of industrial collaborative robotics. 2018 2 - 2019 - Human\u2013Robot Collaboration in Manufacturing Applications: A Review Concept of cobots invented in 1996 [2] Classification of human robot interaction [7] Coexistence - Human operator and cobot are in the ame environment but do not interact with each other Synchronised - Human operator and cobot work in the same workspace, but at different times Cooperation - Human operator and cobot work in the same workspace at the same time, though focusing on separate tasks Collaboration - Human operator and the cobot must execute a task together, the action of the one has immediate consequences on the other, thaks to special sensors and vision systems Other classifications [8-11] Safety requirements for cobots Safety-rated Monitored Stop (SMS) - used to cease robot motion in the collabortice workspace before an operator enter the collaborative workspace Hand-guiding (HG) - where an operator uses a hand-operated device, locate at or nead the robot end-effector, to transmit motion commands to the robot Speed and separation monitoring (SSM) - where the robot system and operator may move concurrently in the collaborative workspace. During robot motion, the orbot system never gets closer to the operator than the protective separaton distance Power and force limitting (PFL) - where the robot system shall be designed to adequatly reduce risk to an operator by not exceeding the applicable threshlod limit values Defined in [13], cobots should be equipped with additional features such as force and toque sensors, force limits, vision systems (cameras), laser systems, anti-collision systems, recognition of voice commands, and / or system to coordinate the actions of human operators with their motion Robot learning from demonstratoin [15] - IMPORTANTE Table comparing humans, cobots and tobots Assembly - attatching 2 or more components Placement - positiong each part in the proper position Handling - manipulation of the picked part Picking - tacking from the feeding point Collaborative robots are especially advantageous for assembly tasks, particularly if the task is executed with a human operator. They are also suitable for pick and place applications, though the adoption of a traditional robot or a handling system can offer better results in terms of speed, precision, and payload Aplications of cobots in this review Assembly - when the cobot collaborated with the operator in an assembly process Human Assistance - when the cobot acts as an ergonomic support for the operator Machine Tending - when the cobot performs loading / unloading operations Physical human-robot interaction in 6DOF [28] - IMPORTANTE End-effector precise hand-guiding for collaborative robots [30] - IMPORTANTE Results of the review Cobots are being researched more than tobots The most used control system is vision The most used methodologie was hand guiding but the others were aso used The most researched task was assembly, by a large margin To increase safety, productivity and task performance, researchers will need to improve planners, environment and task understanding, operator intention understanding and ergonomic cell setups To imporve HRI systems, common future work focuses on increasing the robots' and operators' awareness of the task and environment by object redognition and integrating multi-modal sensing in an intuitive manner for the operator Trends of Market Robot market is going ot grow The fall in robot prices has led to a growing market for cobots Small and medium sized enterprises could not afford robotic applications due to the high capital costs Trust-based compliant robot-human handovers of payloads [29] - IMPORTANTE Table with the reviewed papers Papers Para Ler [15] - Robot learning from demonstration in robotic assembly: A survey. 2018 [28] - Physical human\u2013robot interaction (pHRI) in 6 DOF with asymmetric cooperation. 2017 [29] - Trust-based compliant robot-human handovers of payloads in collaborative assembly in flexible manufacturing. 2016 [30] - End-effector precise hand-guiding for collaborative robots. 2017","title":"Related Work"},{"location":"related_work/#state-of-the-art-research","text":"","title":"State of The Art Research"},{"location":"related_work/#1-2019-humanrobot-interaction-in-industrial-collaborative-robotics-a-literature-review-of-the-decade","text":"HRI - the process of conveying human intentions and interpreting task descriptions into a sequence of robot motions complying with robot capabilities and working requirements","title":"1 - 2019 - Human\u2013robot interaction in industrial collaborative robotics: a literature review of the decade"},{"location":"related_work/#criteria-for-hri","text":"Workspace: the overlapping space in the working range of human and robot is described as the common workspace. Working time: it is defined as the time the participant is working inside the workspace. Aim: every entity of the interacting team has an aim to achieve. This aim can match or mismatch with the other one. Contact: since human and robot share the same workspace, they may come into contact with each other either [16] (i) occasionally or by accident if normal operation is intended to be without contact, or (ii) on purpose if the operator is supposed to work in contact with the robot, exchanging forces and cooperating in action upon on the environment.","title":"Criteria for HRI"},{"location":"related_work/#classification-of-hri","text":"Human\u2013Robot Coexistence (HRCx) , also called coaction, is defined [17] as the capability of sharing the dynamic workspace between humans and robots without a common task (operate on dissimilar tasks) [18,19] or, without requiring mutual contact or coordination of actions [20] and intentions (human and robot may have different aims) [21]. It is generally limited to collisions avoidance. Human\u2013Robot Cooperation (HRCp) acts on a higher level [22] than HRCx. In such a case, humans and robots are working on the same purpose and fulfill the requirements of time and space, simultaneously. The cooperation requires thus advanced technologies such as force-feedback sensing or advanced machine vision [1,17], and far more sensing techniques for collision detection and avoidance. Human\u2013Robot Collaboration (HRC) is the feature of performing a complex task with direct human inter-action in two different modalities [21]: (i) Physical collaboration where an explicit and intentional contact with forces exchange exists between human and robot [23]. By measuring or estimating these forces/torques [10], the robot can predict human motion intentions and react accordingly [24,25]. (ii) Contactless collaboration where no physical interaction exists. In such a case, actions are coordinated from information exchange which can be achieved via direct communication (speech, gestures, etc.), or indirect communication (intentions recognition, eye gaze direction, facial expressions, etc.) [26,27]. In such scenarios, the operator performs task parts requiring dexterity or decision-making, while the robot realizes parts that are not well suited to direct human involvement (repetitive or high-force applications, chemical deposition, precision placement, etc.) Boa tabela de compara\u00e7\u00e3o de artigos","title":"Classification of HRI"},{"location":"related_work/#safety-in-industrial-robots","text":"Distributed real-time approach based on a 3D simulation [117] 121, 122, 123, 304 Real-time collision avoidance approach based on depth sensor [119] Pre-collision algorithms and virtual reality tools [154] Cap\u00edtulo com bu\u00e9 conteudo em refer\u00eancias","title":"Safety in Industrial Robots"},{"location":"related_work/#cognitive-human-robot-interactions","text":"Human actions recognition [192-194] Gestures recognition [201] Control interface to teleoperate robot based on hand gestures using ROS [304] Faces Recognition [202] Voice Commanding [206] Social gaze and social acceptance [195]","title":"Cognitive Human Robot Interactions"},{"location":"related_work/#robot-programming-approaches","text":"Generation of Robotic Skills [216] Augmented and Virtual Reality [215] On-line Programming [217] Programming by Demonstration Muitas refer\u00eancias sobre ensinar robots a fazer tarefas apenas por demonstra\u00e7\u00e3o","title":"Robot Programming Approaches"},{"location":"related_work/#human-robot-tasks-allocation","text":"Ontology-based Knowledge Simplify user interface [93, 222] Generic knowledge based system architecture for cobots [40] Creating high-level tasks plans Behavior Trees [228] CoSTAR framework [229] Skill Based System software in ROS [304] XRob platfoem for HRI [230] Architecture for interactive multi-modal industrial HRI [231] Tasks Allocation and Scheduling Decision-making method that allows human-robot task allocation integrated within ROS [197] Allocating tasks to humans and robots for cell manufactoring [235] Analytic Hirarchy Process as a decision-making approach and Hierarchical Task Analysis [324]","title":"Human Robot Tasks Allocation"},{"location":"related_work/#fault-tolerance","text":"Error Detection Error Diagnosis Recovery","title":"Fault Tolerance"},{"location":"related_work/#papers-para-ler","text":"[7] - Human centered assistance applications for the working environment of the future. 2015 [14] - Evaluation of flexible graphical user interface for intuitive human robot interactions. 2014 [18] - Integration of active and passive compliance control for safe human-robot coexistence. 2009 [19] - A design approach for incorporating task coordination for human-robot coexistence within assembly systems. 2015 [21] - Integrated control for PHRI: collision avoidance, detection, reaction and collaboration. 2012 [22] - A brief review on safety strategies of physical human-robot interaction. 2019 [23] - A depth space approach for evaluating distance to objects. 2015 [24] - Multimodal control for human-robot cooperation. 2013 [27] - Planning safe and legible hand-over motions for human-robot interaction. 2010 [28] - Study on application of a human-robot collaborative system using hand-guiding in a production line. 2016 [44] - Ros based coordination of human robot cooperative assembly tasks. 2015 [49] - Human-robot physical interaction and collaboration using an industrial robot with a closed control architecture. 2013 [55] - Optimized assistive human\u2013robot interaction using reinforcement learning. 2016 [60] - Introducing robots without creating fear of unemployment and high cost in industries. 2018 [70] - Human-robot collaboration for tooling path guidance. 2016 [88] - Real-time computation of distance to dynamic obstacles with multiple depth sensors. 2016 [100] - Working together: a review on safe human-robot collaboration in industrial environments. 2017 [104] - Toward safe human robot collaboration by using multiple kinects based real-time human tracking. 2014 [117] - A real time distributed approach to collision avoidance for industrial manipulators. 2014 [119] - A depth space approach to human-robot collision avoidance. 2012 [124] - A general procedure for collision detection between an industrial robot and the environment. 2015 [167] - Cooperative tasks between humans and robots in industrial environments. 2012 [170] - Safety-aware trajectory scaling for human-robot collaboration with prediction of human occupancy. 2015 [190] - Design of a collaborative architecture for human-robot assembly tasks. 2017 [191] - A user-adaptive gesture recognition system applied to human-robot collaboration in factories. 2016 [192] - Action recognition for human robot interaction in industrial applications. 2015 [195] - A proposed gesture set for the control of industrial collaborative robots. 2012 [197] - On a human-robot collaboration in an assembly cell. 2017 [200] - Dynamic time warping for gesture-based user identification and authentication with kinect. 2013 [217] - Intuitive and model-based on-line programming of industrial robots: a modular on-line programming environment. 2008 [218] - Spatial programming for industrial robots through task demonstration. 2013 [221] - Human\u2013robot interaction review and challenges on task planning and programming. 2016 [229] - Costar: instructing collaborative robots with behavior trees and vision. 2017 [288] - How human-robot teamwork will upend manufacturing. 2014 [293] - Manual guidance for industrial robot programming. 2015 [310] - On a new generation of torque controlled light-weight robots. 2001 [319] - Collision-free motion planning for human-robot collaborative safety under cartesian constraint. 2018 [321] - Survey on human\u2013robot collaboration in industrial settings: safety, intuitive interfaces and applications. 2018 [325] - Key challenges and open issues of industrial collaborative robotics. 2018","title":"Papers Para Ler"},{"location":"related_work/#2-2019-humanrobot-collaboration-in-manufacturing-applications-a-review","text":"Concept of cobots invented in 1996 [2] Classification of human robot interaction [7] Coexistence - Human operator and cobot are in the ame environment but do not interact with each other Synchronised - Human operator and cobot work in the same workspace, but at different times Cooperation - Human operator and cobot work in the same workspace at the same time, though focusing on separate tasks Collaboration - Human operator and the cobot must execute a task together, the action of the one has immediate consequences on the other, thaks to special sensors and vision systems Other classifications [8-11] Safety requirements for cobots Safety-rated Monitored Stop (SMS) - used to cease robot motion in the collabortice workspace before an operator enter the collaborative workspace Hand-guiding (HG) - where an operator uses a hand-operated device, locate at or nead the robot end-effector, to transmit motion commands to the robot Speed and separation monitoring (SSM) - where the robot system and operator may move concurrently in the collaborative workspace. During robot motion, the orbot system never gets closer to the operator than the protective separaton distance Power and force limitting (PFL) - where the robot system shall be designed to adequatly reduce risk to an operator by not exceeding the applicable threshlod limit values Defined in [13], cobots should be equipped with additional features such as force and toque sensors, force limits, vision systems (cameras), laser systems, anti-collision systems, recognition of voice commands, and / or system to coordinate the actions of human operators with their motion Robot learning from demonstratoin [15] - IMPORTANTE Table comparing humans, cobots and tobots Assembly - attatching 2 or more components Placement - positiong each part in the proper position Handling - manipulation of the picked part Picking - tacking from the feeding point Collaborative robots are especially advantageous for assembly tasks, particularly if the task is executed with a human operator. They are also suitable for pick and place applications, though the adoption of a traditional robot or a handling system can offer better results in terms of speed, precision, and payload Aplications of cobots in this review Assembly - when the cobot collaborated with the operator in an assembly process Human Assistance - when the cobot acts as an ergonomic support for the operator Machine Tending - when the cobot performs loading / unloading operations Physical human-robot interaction in 6DOF [28] - IMPORTANTE End-effector precise hand-guiding for collaborative robots [30] - IMPORTANTE Results of the review Cobots are being researched more than tobots The most used control system is vision The most used methodologie was hand guiding but the others were aso used The most researched task was assembly, by a large margin To increase safety, productivity and task performance, researchers will need to improve planners, environment and task understanding, operator intention understanding and ergonomic cell setups To imporve HRI systems, common future work focuses on increasing the robots' and operators' awareness of the task and environment by object redognition and integrating multi-modal sensing in an intuitive manner for the operator Trends of Market Robot market is going ot grow The fall in robot prices has led to a growing market for cobots Small and medium sized enterprises could not afford robotic applications due to the high capital costs Trust-based compliant robot-human handovers of payloads [29] - IMPORTANTE Table with the reviewed papers","title":"2 - 2019 - Human\u2013Robot Collaboration in Manufacturing Applications: A Review"},{"location":"related_work/#papers-para-ler_1","text":"[15] - Robot learning from demonstration in robotic assembly: A survey. 2018 [28] - Physical human\u2013robot interaction (pHRI) in 6 DOF with asymmetric cooperation. 2017 [29] - Trust-based compliant robot-human handovers of payloads in collaborative assembly in flexible manufacturing. 2016 [30] - End-effector precise hand-guiding for collaborative robots. 2017","title":"Papers Para Ler"},{"location":"results/","text":"","title":"Experiments and Results"},{"location":"safe_planning/","text":"Safe Path Planing ...","title":"Safe Path Planning"},{"location":"safe_planning/#safe-path-planing","text":"","title":"Safe Path Planing"},{"location":"safe_planning/#_1","text":"","title":"..."},{"location":"setup/","text":"Collaborative Setup Robotic Manipulator Vision and Sensors Shared Workspace and Tools","title":"Collaborative Setup"},{"location":"setup/#collaborative-setup","text":"","title":"Collaborative Setup"},{"location":"setup/#robotic-manipulator","text":"","title":"Robotic Manipulator"},{"location":"setup/#vision-and-sensors","text":"","title":"Vision and Sensors"},{"location":"setup/#shared-workspace-and-tools","text":"","title":"Shared Workspace and Tools"},{"location":"soa/","text":"Background and Related Work Colaborative Robotics Predominant Technologies Existing Approaches","title":"Background and Related Work"},{"location":"soa/#background-and-related-work","text":"","title":"Background and Related Work"},{"location":"soa/#colaborative-robotics","text":"","title":"Colaborative Robotics"},{"location":"soa/#predominant-technologies","text":"","title":"Predominant Technologies"},{"location":"soa/#existing-approaches","text":"","title":"Existing Approaches"},{"location":"struct/","text":"Structure 1 - Introduction Motivation Objectives Outline 2 - Background and Related Work Colaborative Robotics O que \u00e9? Como? Onde? Conhecimento te\u00f3rico necess\u00e1rio para abrodar o tema Predominant Technologies Tecnologias (software) frequentemente utilizado Existing Approaches Trabalhos realizados no tema 3 - Collaborative Setup Robotic Manipulator Vision and Sensors Shared Workspace and Tools 4 - Hand Guiding Force / Torque Sensor Correction End Effector Weight Compensation Force / Torque to Robot Motion 5 - Safe Path Planing ... 6 - Collaborative Tasks Tool Transfer Object Lifting Assistant ... 7 - Experiments and Results 8 - Conclusion Material Developed Interaction with robot through gripper taps in multiple directions Time series analysis of FT to detect interaction with the robot rqt_sami - GUI plugin to control de robot from a computer based in iris_sami functionalities rqt_cobot - GUI plugin to interact with the robot based on the colaborative tasks of iris_cobot Visual feedback through gripper LEDs Plotjuggler integration ros_smach global state machine","title":"Structure"},{"location":"struct/#structure","text":"","title":"Structure"},{"location":"struct/#1-introduction","text":"","title":"1 - Introduction"},{"location":"struct/#motivation","text":"","title":"Motivation"},{"location":"struct/#objectives","text":"","title":"Objectives"},{"location":"struct/#outline","text":"","title":"Outline"},{"location":"struct/#2-background-and-related-work","text":"","title":"2 - Background and Related Work"},{"location":"struct/#colaborative-robotics","text":"O que \u00e9? Como? Onde? Conhecimento te\u00f3rico necess\u00e1rio para abrodar o tema","title":"Colaborative Robotics"},{"location":"struct/#predominant-technologies","text":"Tecnologias (software) frequentemente utilizado","title":"Predominant Technologies"},{"location":"struct/#existing-approaches","text":"Trabalhos realizados no tema","title":"Existing Approaches"},{"location":"struct/#3-collaborative-setup","text":"","title":"3 - Collaborative Setup"},{"location":"struct/#robotic-manipulator","text":"","title":"Robotic Manipulator"},{"location":"struct/#vision-and-sensors","text":"","title":"Vision and Sensors"},{"location":"struct/#shared-workspace-and-tools","text":"","title":"Shared Workspace and Tools"},{"location":"struct/#4-hand-guiding","text":"","title":"4 - Hand Guiding"},{"location":"struct/#force-torque-sensor-correction","text":"","title":"Force / Torque Sensor Correction"},{"location":"struct/#end-effector-weight-compensation","text":"","title":"End Effector Weight Compensation"},{"location":"struct/#force-torque-to-robot-motion","text":"","title":"Force / Torque to Robot Motion"},{"location":"struct/#5-safe-path-planing","text":"","title":"5 - Safe Path Planing"},{"location":"struct/#_1","text":"","title":"..."},{"location":"struct/#6-collaborative-tasks","text":"","title":"6 - Collaborative Tasks"},{"location":"struct/#tool-transfer","text":"","title":"Tool Transfer"},{"location":"struct/#object-lifting-assistant","text":"","title":"Object Lifting Assistant"},{"location":"struct/#_2","text":"","title":"..."},{"location":"struct/#7-experiments-and-results","text":"","title":"7 - Experiments and Results"},{"location":"struct/#8-conclusion","text":"","title":"8 - Conclusion"},{"location":"struct/#material-developed","text":"Interaction with robot through gripper taps in multiple directions Time series analysis of FT to detect interaction with the robot rqt_sami - GUI plugin to control de robot from a computer based in iris_sami functionalities rqt_cobot - GUI plugin to interact with the robot based on the colaborative tasks of iris_cobot Visual feedback through gripper LEDs Plotjuggler integration ros_smach global state machine","title":"Material Developed"},{"location":"tasks/","text":"Collaborative Tasks Tool Transfer Object Lifting Assistant ...","title":"Collaborative Tasks"},{"location":"tasks/#collaborative-tasks","text":"","title":"Collaborative Tasks"},{"location":"tasks/#tool-transfer","text":"","title":"Tool Transfer"},{"location":"tasks/#object-lifting-assistant","text":"","title":"Object Lifting Assistant"},{"location":"tasks/#_1","text":"","title":"..."}]}